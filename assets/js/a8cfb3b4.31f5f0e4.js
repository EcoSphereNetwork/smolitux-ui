"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[976],{6105:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>u,frontMatter:()=>s,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"features/voice-control/tensorflow-integration","title":"TensorFlow.js-Integration f\xfcr Sprachsteuerung","description":"Diese Dokumentation beschreibt die Integration von TensorFlow.js in die Sprachsteuerungsfunktionalit\xe4t der Smolitux-UI-Bibliothek. Sie enth\xe4lt detaillierte Anweisungen zur Implementierung, Optimierung und Anpassung von TensorFlow.js-basierten Spracherkennungsmodellen.","source":"@site/docs/features/voice-control/tensorflow-integration.md","sourceDirName":"features/voice-control","slug":"/features/voice-control/tensorflow-integration","permalink":"/smolitux-ui/docs/features/voice-control/tensorflow-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/EcoSphereNetwork/smolitux-ui/tree/main/docs/docs/features/voice-control/tensorflow-integration.md","tags":[],"version":"current","frontMatter":{},"sidebar":"wikiSidebar","previous":{"title":"Implementierungsleitfaden f\xfcr Sprachsteuerung in Smolitux-UI","permalink":"/smolitux-ui/docs/features/voice-control/implementation-guide"},"next":{"title":"Sprachsteuerungsarchitektur f\xfcr Smolitux-UI","permalink":"/smolitux-ui/docs/features/voice-control/voice-control-architecture"}}');var i=r(4848),t=r(8453);const s={},l="TensorFlow.js-Integration f\xfcr Sprachsteuerung",a={},d=[{value:"Inhaltsverzeichnis",id:"inhaltsverzeichnis",level:2},{value:"\xdcbersicht",id:"\xfcbersicht",level:2},{value:"Vorteile der TensorFlow.js-Integration",id:"vorteile-der-tensorflowjs-integration",level:3},{value:"Nachteile",id:"nachteile",level:3},{value:"Voraussetzungen",id:"voraussetzungen",level:2},{value:"Architektur",id:"architektur",level:2},{value:"Implementierung",id:"implementierung",level:2},{value:"TensorFlow Recognition Engine",id:"tensorflow-recognition-engine",level:3},{value:"WebWorker-Integration",id:"webworker-integration",level:3},{value:"Modellverwaltung",id:"modellverwaltung",level:3},{value:"Modelltraining und -anpassung",id:"modelltraining-und--anpassung",level:2},{value:"Transfer Learning mit TensorFlow.js",id:"transfer-learning-mit-tensorflowjs",level:3},{value:"Beispiel: Trainieren eines benutzerdefinierten Modells",id:"beispiel-trainieren-eines-benutzerdefinierten-modells",level:3},{value:"Leistungsoptimierung",id:"leistungsoptimierung",level:2},{value:"Modellquantisierung",id:"modellquantisierung",level:3},{value:"WebGL-Beschleunigung",id:"webgl-beschleunigung",level:3},{value:"Lazy Loading",id:"lazy-loading",level:3},{value:"Offline-Unterst\xfctzung",id:"offline-unterst\xfctzung",level:2},{value:"Mehrsprachige Unterst\xfctzung",id:"mehrsprachige-unterst\xfctzung",level:2},{value:"Erweiterte Funktionen",id:"erweiterte-funktionen",level:2},{value:"Kontinuierliche Spracherkennung",id:"kontinuierliche-spracherkennung",level:3},{value:"Sprachsynthese f\xfcr Feedback",id:"sprachsynthese-f\xfcr-feedback",level:3},{value:"Fehlerbehebung",id:"fehlerbehebung",level:2},{value:"H\xe4ufige Probleme und L\xf6sungen",id:"h\xe4ufige-probleme-und-l\xf6sungen",level:3},{value:"Beispiele",id:"beispiele",level:2},{value:"Grundlegende Verwendung",id:"grundlegende-verwendung",level:3},{value:"Erweiterte Verwendung mit benutzerdefinierten Modellen",id:"erweiterte-verwendung-mit-benutzerdefinierten-modellen",level:3},{value:"Vollst\xe4ndiges Beispiel mit Modelltraining",id:"vollst\xe4ndiges-beispiel-mit-modelltraining",level:3}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"tensorflowjs-integration-f\xfcr-sprachsteuerung",children:"TensorFlow.js-Integration f\xfcr Sprachsteuerung"})}),"\n",(0,i.jsx)(n.p,{children:"Diese Dokumentation beschreibt die Integration von TensorFlow.js in die Sprachsteuerungsfunktionalit\xe4t der Smolitux-UI-Bibliothek. Sie enth\xe4lt detaillierte Anweisungen zur Implementierung, Optimierung und Anpassung von TensorFlow.js-basierten Spracherkennungsmodellen."}),"\n",(0,i.jsx)(n.h2,{id:"inhaltsverzeichnis",children:"Inhaltsverzeichnis"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#%C3%BCbersicht",children:"\xdcbersicht"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#voraussetzungen",children:"Voraussetzungen"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#architektur",children:"Architektur"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#implementierung",children:"Implementierung"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#tensorflow-recognition-engine",children:"TensorFlow Recognition Engine"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#modellverwaltung",children:"Modellverwaltung"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#webworker-integration",children:"WebWorker-Integration"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#modelltraining-und--anpassung",children:"Modelltraining und -anpassung"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#leistungsoptimierung",children:"Leistungsoptimierung"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#offline-unterst%C3%BCtzung",children:"Offline-Unterst\xfctzung"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#mehrsprachige-unterst%C3%BCtzung",children:"Mehrsprachige Unterst\xfctzung"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#erweiterte-funktionen",children:"Erweiterte Funktionen"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#fehlerbehebung",children:"Fehlerbehebung"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#beispiele",children:"Beispiele"})}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"\xfcbersicht",children:"\xdcbersicht"}),"\n",(0,i.jsx)(n.p,{children:"Die Integration von TensorFlow.js in die Sprachsteuerungsfunktionalit\xe4t erm\xf6glicht eine lokale, offline-f\xe4hige Spracherkennung mit anpassbaren Modellen. Im Gegensatz zur Web Speech API, die in einigen Browsern eine Internetverbindung erfordert, kann TensorFlow.js vollst\xe4ndig lokal ausgef\xfchrt werden und bietet mehr Kontrolle \xfcber die Erkennungsparameter."}),"\n",(0,i.jsx)(n.h3,{id:"vorteile-der-tensorflowjs-integration",children:"Vorteile der TensorFlow.js-Integration"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Offline-Funktionalit\xe4t"}),": Spracherkennung funktioniert auch ohne Internetverbindung"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Anpassbare Modelle"}),": M\xf6glichkeit, eigene Modelle zu trainieren und anzupassen"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Datenschutz"}),": Audiodaten werden lokal verarbeitet und nicht an externe Server gesendet"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Konsistente Erfahrung"}),": Gleiche Funktionalit\xe4t in allen modernen Browsern"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"nachteile",children:"Nachteile"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gr\xf6\xdfere Paketgr\xf6\xdfe"}),": TensorFlow.js und Modelle erh\xf6hen die Anwendungsgr\xf6\xdfe"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"H\xf6here Ressourcenanforderungen"}),": CPU/GPU-Nutzung ist h\xf6her als bei nativen APIs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Begrenzte Vokabulargr\xf6\xdfe"}),": Vortrainierte Modelle unterst\xfctzen nur eine begrenzte Anzahl von Befehlen"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"voraussetzungen",children:"Voraussetzungen"}),"\n",(0,i.jsx)(n.p,{children:"Bevor Sie mit der TensorFlow.js-Integration beginnen, stellen Sie sicher, dass Sie folgende Abh\xe4ngigkeiten installiert haben:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"npm install --save @tensorflow/tfjs @tensorflow-models/speech-commands\n"})}),"\n",(0,i.jsx)(n.p,{children:"F\xfcr TypeScript-Unterst\xfctzung:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"npm install --save-dev @types/tensorflow__tfjs @types/tensorflow-models__speech-commands\n"})}),"\n",(0,i.jsx)(n.h2,{id:"architektur",children:"Architektur"}),"\n",(0,i.jsx)(n.p,{children:"Die TensorFlow.js-Integration in die Sprachsteuerungsarchitektur folgt diesem Muster:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  VoiceControlProvider                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    VoiceControlManager                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                TensorFlowRecognitionEngine                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 ModelLoader \u2502  \u2502 Recognizer  \u2502  \u2502 CommandMapper       \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    TensorFlow.js Core                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               Speech Commands Model (WebWorker)             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsx)(n.h2,{id:"implementierung",children:"Implementierung"}),"\n",(0,i.jsx)(n.h3,{id:"tensorflow-recognition-engine",children:"TensorFlow Recognition Engine"}),"\n",(0,i.jsxs)(n.p,{children:["Die ",(0,i.jsx)(n.code,{children:"TensorFlowRecognitionEngine"})," implementiert die ",(0,i.jsx)(n.code,{children:"RecognitionEngine"}),"-Schnittstelle und verwendet TensorFlow.js f\xfcr die Spracherkennung."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/engines/TensorFlowRecognitionEngine.ts\nimport * as tf from '@tensorflow/tfjs';\nimport * as speech from '@tensorflow-models/speech-commands';\nimport { RecognitionEngine } from './RecognitionEngine';\n\nexport interface TensorFlowRecognitionOptions {\n  modelType?: 'BROWSER_FFT' | '18W';\n  vocabulary?: 'directional4w' | 'directional8w' | 'digits' | 'general' | string[];\n  customModelUrl?: string;\n  scoreThreshold?: number;\n  includeSpectogram?: boolean;\n  overlapFactor?: number;\n  probabilityThreshold?: number;\n  invokeCallbackOnNoiseAndUnknown?: boolean;\n  suppressionTimeMillis?: number;\n}\n\nexport class TensorFlowRecognitionEngine implements RecognitionEngine {\n  private model: speech.SpeechCommandRecognizer | null = null;\n  private listening = false;\n  private commandVocabulary: string[] = [];\n  private options: TensorFlowRecognitionOptions;\n  private worker: Worker | null = null;\n  private useWorker: boolean;\n\n  public onResult: (text: string) => void = () => {};\n  public onStateChange: (isListening: boolean) => void = () => {};\n  public onError: (error: Error) => void = () => {};\n\n  constructor(options: TensorFlowRecognitionOptions = {}, useWorker = false) {\n    this.options = {\n      modelType: 'BROWSER_FFT',\n      vocabulary: 'general',\n      scoreThreshold: 0.75,\n      includeSpectogram: false,\n      overlapFactor: 0.5,\n      probabilityThreshold: 0.75,\n      invokeCallbackOnNoiseAndUnknown: false,\n      suppressionTimeMillis: 100,\n      ...options\n    };\n    \n    this.useWorker = useWorker;\n    \n    if (useWorker) {\n      this.initWorker();\n    } else {\n      this.initModel();\n    }\n  }\n\n  private async initModel() {\n    try {\n      await tf.ready();\n      \n      // Verwende WebGL-Backend f\xfcr GPU-Beschleunigung, wenn verf\xfcgbar\n      if (tf.getBackend() !== 'webgl' && tf.ENV.flagRegistry.HAS_WEBGL) {\n        await tf.setBackend('webgl');\n      }\n      \n      // Lade das Modell\n      const modelOptions: speech.SpeechCommandsRecognizerOptions = {\n        vocabulary: this.options.vocabulary as any,\n        customModelUrl: this.options.customModelUrl\n      };\n      \n      this.model = speech.create(\n        this.options.modelType as any, \n        undefined, \n        modelOptions\n      );\n      \n      await this.model.ensureModelLoaded();\n      \n      // Hole verf\xfcgbare Befehle\n      this.commandVocabulary = this.model.wordLabels();\n      \n      // Konfiguriere das Modell\n      this.model.params().scoreThreshold = this.options.scoreThreshold || 0.75;\n      \n      console.log('TensorFlow.js speech model loaded successfully');\n      console.log('Available commands:', this.commandVocabulary);\n    } catch (error) {\n      console.error('Failed to load TensorFlow.js speech model:', error);\n      this.onError(error as Error);\n    }\n  }\n\n  private initWorker() {\n    try {\n      // Erstelle einen WebWorker f\xfcr die Spracherkennung\n      this.worker = new Worker(new URL('../workers/speechRecognitionWorker.ts', import.meta.url));\n      \n      // Sende Initialisierungsparameter an den Worker\n      this.worker.postMessage({\n        type: 'init',\n        options: this.options\n      });\n      \n      // H\xf6re auf Nachrichten vom Worker\n      this.worker.addEventListener('message', (event) => {\n        const { type, data } = event.data;\n        \n        switch (type) {\n          case 'modelLoaded':\n            this.commandVocabulary = data.commands;\n            console.log('TensorFlow.js speech model loaded in worker');\n            console.log('Available commands:', this.commandVocabulary);\n            break;\n          case 'result':\n            this.onResult(data.command);\n            break;\n          case 'listening':\n            this.listening = data.status;\n            this.onStateChange(data.status);\n            break;\n          case 'error':\n            console.error('Speech recognition worker error:', data.error);\n            this.onError(new Error(data.error));\n            break;\n        }\n      });\n      \n      // Behandle Worker-Fehler\n      this.worker.addEventListener('error', (error) => {\n        console.error('Speech recognition worker error:', error);\n        this.onError(new Error('Worker error: ' + error.message));\n      });\n    } catch (error) {\n      console.error('Failed to initialize speech recognition worker:', error);\n      this.onError(error as Error);\n      \n      // Fallback auf direktes Modell\n      this.useWorker = false;\n      this.initModel();\n    }\n  }\n\n  public async start() {\n    if (this.useWorker) {\n      if (this.worker && !this.listening) {\n        this.worker.postMessage({ type: 'start' });\n      }\n    } else {\n      if (!this.model) {\n        await this.initModel();\n      }\n      \n      if (this.model && !this.listening) {\n        this.listening = true;\n        this.onStateChange(true);\n        \n        this.model.listen(\n          result => {\n            const scores = Array.from(result.scores);\n            const maxScore = Math.max(...scores);\n            const maxScoreIndex = scores.indexOf(maxScore);\n            \n            if (maxScore > (this.options.scoreThreshold || 0.75)) {\n              const recognizedCommand = this.commandVocabulary[maxScoreIndex];\n              this.onResult(recognizedCommand);\n            }\n          },\n          {\n            includeSpectrogram: this.options.includeSpectogram,\n            probabilityThreshold: this.options.probabilityThreshold,\n            invokeCallbackOnNoiseAndUnknown: this.options.invokeCallbackOnNoiseAndUnknown,\n            overlapFactor: this.options.overlapFactor,\n            suppressionTimeMillis: this.options.suppressionTimeMillis\n          }\n        );\n      }\n    }\n  }\n\n  public stop() {\n    if (this.useWorker) {\n      if (this.worker && this.listening) {\n        this.worker.postMessage({ type: 'stop' });\n      }\n    } else {\n      if (this.model && this.listening) {\n        this.model.stopListening();\n        this.listening = false;\n        this.onStateChange(false);\n      }\n    }\n  }\n\n  public cleanup() {\n    this.stop();\n    \n    if (this.useWorker) {\n      if (this.worker) {\n        this.worker.postMessage({ type: 'cleanup' });\n        this.worker.terminate();\n        this.worker = null;\n      }\n    } else {\n      if (this.model) {\n        this.model.stopListening();\n        this.model = null;\n      }\n    }\n  }\n\n  public getAvailableCommands(): string[] {\n    return [...this.commandVocabulary];\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"webworker-integration",children:"WebWorker-Integration"}),"\n",(0,i.jsx)(n.p,{children:"F\xfcr eine bessere Leistung k\xf6nnen Sie die Spracherkennung in einem WebWorker ausf\xfchren:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/workers/speechRecognitionWorker.ts\nimport * as tf from '@tensorflow/tfjs';\nimport * as speech from '@tensorflow-models/speech-commands';\n\nlet model: speech.SpeechCommandRecognizer | null = null;\nlet listening = false;\nlet commandVocabulary: string[] = [];\nlet options = {\n  modelType: 'BROWSER_FFT',\n  vocabulary: 'general',\n  scoreThreshold: 0.75,\n  includeSpectogram: false,\n  overlapFactor: 0.5,\n  probabilityThreshold: 0.75,\n  invokeCallbackOnNoiseAndUnknown: false,\n  suppressionTimeMillis: 100\n};\n\nasync function initModel() {\n  try {\n    await tf.ready();\n    \n    // Verwende WebGL-Backend f\xfcr GPU-Beschleunigung, wenn verf\xfcgbar\n    if (tf.getBackend() !== 'webgl' && tf.ENV.flagRegistry.HAS_WEBGL) {\n      await tf.setBackend('webgl');\n    }\n    \n    // Lade das Modell\n    const modelOptions: speech.SpeechCommandsRecognizerOptions = {\n      vocabulary: options.vocabulary as any,\n      customModelUrl: options.customModelUrl\n    };\n    \n    model = speech.create(\n      options.modelType as any, \n      undefined, \n      modelOptions\n    );\n    \n    await model.ensureModelLoaded();\n    \n    // Hole verf\xfcgbare Befehle\n    commandVocabulary = model.wordLabels();\n    \n    // Konfiguriere das Modell\n    model.params().scoreThreshold = options.scoreThreshold || 0.75;\n    \n    // Informiere den Hauptthread, dass das Modell geladen ist\n    self.postMessage({ \n      type: 'modelLoaded', \n      data: { commands: commandVocabulary } \n    });\n  } catch (error) {\n    self.postMessage({ \n      type: 'error', \n      data: { error: error.message } \n    });\n  }\n}\n\nfunction startListening() {\n  if (!model || listening) return;\n  \n  listening = true;\n  self.postMessage({ type: 'listening', data: { status: true } });\n  \n  model.listen(\n    result => {\n      const scores = Array.from(result.scores);\n      const maxScore = Math.max(...scores);\n      const maxScoreIndex = scores.indexOf(maxScore);\n      \n      if (maxScore > (options.scoreThreshold || 0.75)) {\n        const recognizedCommand = commandVocabulary[maxScoreIndex];\n        self.postMessage({ \n          type: 'result', \n          data: { \n            command: recognizedCommand,\n            score: maxScore,\n            allScores: scores\n          } \n        });\n      }\n    },\n    {\n      includeSpectrogram: options.includeSpectogram,\n      probabilityThreshold: options.probabilityThreshold,\n      invokeCallbackOnNoiseAndUnknown: options.invokeCallbackOnNoiseAndUnknown,\n      overlapFactor: options.overlapFactor,\n      suppressionTimeMillis: options.suppressionTimeMillis\n    }\n  );\n}\n\nfunction stopListening() {\n  if (!model || !listening) return;\n  \n  model.stopListening();\n  listening = false;\n  self.postMessage({ type: 'listening', data: { status: false } });\n}\n\nfunction cleanup() {\n  stopListening();\n  model = null;\n  commandVocabulary = [];\n}\n\n// H\xf6re auf Nachrichten vom Hauptthread\nself.addEventListener('message', async (event) => {\n  const { type, options: eventOptions } = event.data;\n  \n  switch (type) {\n    case 'init':\n      if (eventOptions) {\n        options = { ...options, ...eventOptions };\n      }\n      await initModel();\n      break;\n    case 'start':\n      startListening();\n      break;\n    case 'stop':\n      stopListening();\n      break;\n    case 'cleanup':\n      cleanup();\n      break;\n  }\n});\n\n// Informiere den Hauptthread, dass der Worker bereit ist\nself.postMessage({ type: 'ready' });\n"})}),"\n",(0,i.jsx)(n.h3,{id:"modellverwaltung",children:"Modellverwaltung"}),"\n",(0,i.jsxs)(n.p,{children:["F\xfcr eine effiziente Verwaltung verschiedener Modelle k\xf6nnen Sie eine ",(0,i.jsx)(n.code,{children:"ModelManager"}),"-Klasse implementieren:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/models/ModelManager.ts\nimport * as tf from '@tensorflow/tfjs';\n\nexport interface ModelInfo {\n  name: string;\n  url: string;\n  size: number;\n  vocabulary: string[];\n  language: string;\n  description: string;\n}\n\nexport class ModelManager {\n  private models: Map<string, ModelInfo> = new Map();\n  private loadedModels: Map<string, tf.LayersModel> = new Map();\n  \n  constructor() {\n    // Registriere Standard-Modelle\n    this.registerModel({\n      name: 'general-de',\n      url: 'https://storage.googleapis.com/smolitux-models/speech/general-de/model.json',\n      size: 2500000, // ca. 2.5 MB\n      vocabulary: ['ja', 'nein', 'start', 'stop', 'weiter', 'zur\xfcck', '\xf6ffnen', 'schlie\xdfen'],\n      language: 'de-DE',\n      description: 'Deutsches Allgemein-Modell mit grundlegenden Befehlen'\n    });\n    \n    this.registerModel({\n      name: 'general-en',\n      url: 'https://storage.googleapis.com/smolitux-models/speech/general-en/model.json',\n      size: 2500000, // ca. 2.5 MB\n      vocabulary: ['yes', 'no', 'start', 'stop', 'next', 'back', 'open', 'close'],\n      language: 'en-US',\n      description: 'English general model with basic commands'\n    });\n  }\n  \n  public registerModel(modelInfo: ModelInfo) {\n    this.models.set(modelInfo.name, modelInfo);\n  }\n  \n  public getModelInfo(name: string): ModelInfo | undefined {\n    return this.models.get(name);\n  }\n  \n  public async loadModel(name: string): Promise<tf.LayersModel | null> {\n    // Pr\xfcfe, ob das Modell bereits geladen ist\n    if (this.loadedModels.has(name)) {\n      return this.loadedModels.get(name)!;\n    }\n    \n    // Pr\xfcfe, ob das Modell registriert ist\n    const modelInfo = this.models.get(name);\n    if (!modelInfo) {\n      console.error(`Model \"${name}\" is not registered`);\n      return null;\n    }\n    \n    try {\n      // Lade das Modell\n      const model = await tf.loadLayersModel(modelInfo.url);\n      this.loadedModels.set(name, model);\n      return model;\n    } catch (error) {\n      console.error(`Failed to load model \"${name}\":`, error);\n      return null;\n    }\n  }\n  \n  public async unloadModel(name: string): Promise<boolean> {\n    if (!this.loadedModels.has(name)) {\n      return false;\n    }\n    \n    try {\n      const model = this.loadedModels.get(name)!;\n      model.dispose();\n      this.loadedModels.delete(name);\n      return true;\n    } catch (error) {\n      console.error(`Failed to unload model \"${name}\":`, error);\n      return false;\n    }\n  }\n  \n  public getAvailableModels(): ModelInfo[] {\n    return Array.from(this.models.values());\n  }\n  \n  public getLoadedModels(): string[] {\n    return Array.from(this.loadedModels.keys());\n  }\n  \n  public getModelsByLanguage(language: string): ModelInfo[] {\n    return Array.from(this.models.values()).filter(model => model.language === language);\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"modelltraining-und--anpassung",children:"Modelltraining und -anpassung"}),"\n",(0,i.jsx)(n.p,{children:"F\xfcr spezifische Anwendungsf\xe4lle k\xf6nnen Sie eigene Modelle trainieren und in die Sprachsteuerung integrieren."}),"\n",(0,i.jsx)(n.h3,{id:"transfer-learning-mit-tensorflowjs",children:"Transfer Learning mit TensorFlow.js"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/models/ModelTrainer.ts\nimport * as tf from '@tensorflow/tfjs';\nimport * as speech from '@tensorflow-models/speech-commands';\n\nexport interface TrainingOptions {\n  epochs?: number;\n  batchSize?: number;\n  learningRate?: number;\n  validationSplit?: number;\n  callbacks?: tf.CallbackArgs;\n}\n\nexport class ModelTrainer {\n  private recognizer: speech.SpeechCommandRecognizer;\n  private customWords: string[] = [];\n  \n  constructor() {\n    this.recognizer = speech.create('BROWSER_FFT');\n  }\n  \n  public async init() {\n    await this.recognizer.ensureModelLoaded();\n  }\n  \n  public async collectExample(word: string, durationSec = 2): Promise<void> {\n    if (!this.customWords.includes(word)) {\n      this.customWords.push(word);\n    }\n    \n    return new Promise<void>((resolve) => {\n      this.recognizer.collectExample(word, {\n        durationSec,\n        onComplete: () => {\n          console.log(`Collected example for word \"${word}\"`);\n          resolve();\n        }\n      });\n    });\n  }\n  \n  public async train(options: TrainingOptions = {}): Promise<tf.History> {\n    const {\n      epochs = 50,\n      batchSize = 32,\n      learningRate = 0.01,\n      validationSplit = 0.2,\n      callbacks = {}\n    } = options;\n    \n    const trainingOptions: speech.TransferLearnConfig = {\n      epochs,\n      callback: callbacks,\n      batchSize,\n      learningRate,\n      validationSplit\n    };\n    \n    return await this.recognizer.train(trainingOptions);\n  }\n  \n  public async save(format: 'indexeddb' | 'downloads' | 'localstorage' = 'indexeddb', name = 'custom-model'): Promise<tf.io.SaveResult> {\n    let saveResult: tf.io.SaveResult;\n    \n    switch (format) {\n      case 'indexeddb':\n        saveResult = await this.recognizer.save(`indexeddb://${name}`);\n        break;\n      case 'downloads':\n        saveResult = await this.recognizer.save(`downloads://${name}`);\n        break;\n      case 'localstorage':\n        saveResult = await this.recognizer.save(`localstorage://${name}`);\n        break;\n      default:\n        throw new Error(`Unsupported save format: ${format}`);\n    }\n    \n    // Speichere auch die benutzerdefinierten W\xf6rter\n    localStorage.setItem(`${name}-words`, JSON.stringify(this.customWords));\n    \n    return saveResult;\n  }\n  \n  public async load(format: 'indexeddb' | 'localstorage' = 'indexeddb', name = 'custom-model'): Promise<boolean> {\n    try {\n      switch (format) {\n        case 'indexeddb':\n          await this.recognizer.load(`indexeddb://${name}`);\n          break;\n        case 'localstorage':\n          await this.recognizer.load(`localstorage://${name}`);\n          break;\n        default:\n          throw new Error(`Unsupported load format: ${format}`);\n      }\n      \n      // Lade auch die benutzerdefinierten W\xf6rter\n      const wordsJson = localStorage.getItem(`${name}-words`);\n      if (wordsJson) {\n        this.customWords = JSON.parse(wordsJson);\n      }\n      \n      return true;\n    } catch (error) {\n      console.error(`Failed to load model \"${name}\":`, error);\n      return false;\n    }\n  }\n  \n  public getCustomWords(): string[] {\n    return [...this.customWords];\n  }\n  \n  public getExampleCounts(): {[word: string]: number} {\n    return this.recognizer.countExamples();\n  }\n  \n  public clearExamples(word?: string): void {\n    if (word) {\n      this.recognizer.clearExamples(word);\n      \n      // Entferne das Wort aus der Liste, wenn keine Beispiele mehr vorhanden sind\n      const counts = this.recognizer.countExamples();\n      if (!counts[word] || counts[word] === 0) {\n        this.customWords = this.customWords.filter(w => w !== word);\n      }\n    } else {\n      // L\xf6sche alle Beispiele\n      for (const word of this.customWords) {\n        this.recognizer.clearExamples(word);\n      }\n      this.customWords = [];\n    }\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"beispiel-trainieren-eines-benutzerdefinierten-modells",children:"Beispiel: Trainieren eines benutzerdefinierten Modells"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-tsx",children:"import React, { useState, useEffect } from 'react';\nimport { ModelTrainer, TrainingOptions } from '../voice-control/models/ModelTrainer';\n\nconst ModelTrainingComponent: React.FC = () => {\n  const [trainer, setTrainer] = useState<ModelTrainer | null>(null);\n  const [isRecording, setIsRecording] = useState(false);\n  const [currentWord, setCurrentWord] = useState('');\n  const [customWords, setCustomWords] = useState<string[]>([]);\n  const [exampleCounts, setExampleCounts] = useState<{[word: string]: number}>({});\n  const [isTraining, setIsTraining] = useState(false);\n  const [trainingProgress, setTrainingProgress] = useState(0);\n  \n  useEffect(() => {\n    const initTrainer = async () => {\n      const newTrainer = new ModelTrainer();\n      await newTrainer.init();\n      setTrainer(newTrainer);\n    };\n    \n    initTrainer();\n    \n    return () => {\n      // Cleanup\n    };\n  }, []);\n  \n  const handleAddWord = () => {\n    if (currentWord && !customWords.includes(currentWord)) {\n      setCustomWords([...customWords, currentWord]);\n    }\n  };\n  \n  const handleRecordExample = async (word: string) => {\n    if (!trainer) return;\n    \n    setIsRecording(true);\n    \n    try {\n      await trainer.collectExample(word);\n      setExampleCounts(trainer.getExampleCounts());\n    } catch (error) {\n      console.error('Failed to record example:', error);\n    } finally {\n      setIsRecording(false);\n    }\n  };\n  \n  const handleTrain = async () => {\n    if (!trainer) return;\n    \n    setIsTraining(true);\n    setTrainingProgress(0);\n    \n    try {\n      const trainingOptions: TrainingOptions = {\n        epochs: 50,\n        callbacks: {\n          onEpochEnd: (epoch, logs) => {\n            const progress = (epoch + 1) / 50;\n            setTrainingProgress(progress);\n          }\n        }\n      };\n      \n      await trainer.train(trainingOptions);\n      \n      // Speichere das trainierte Modell\n      await trainer.save('indexeddb', 'my-custom-model');\n      \n      alert('Model trained and saved successfully!');\n    } catch (error) {\n      console.error('Failed to train model:', error);\n      alert('Failed to train model: ' + error.message);\n    } finally {\n      setIsTraining(false);\n    }\n  };\n  \n  return (\n    <div className=\"model-training\">\n      <h2>Train Custom Speech Model</h2>\n      \n      <div className=\"add-word\">\n        <input\n          type=\"text\"\n          value={currentWord}\n          onChange={(e) => setCurrentWord(e.target.value)}\n          placeholder=\"Enter a new command word\"\n          disabled={isRecording || isTraining}\n        />\n        <button onClick={handleAddWord} disabled={!currentWord || isRecording || isTraining}>\n          Add Word\n        </button>\n      </div>\n      \n      <div className=\"word-list\">\n        <h3>Custom Words</h3>\n        {customWords.length === 0 ? (\n          <p>No custom words added yet.</p>\n        ) : (\n          <ul>\n            {customWords.map((word) => (\n              <li key={word}>\n                {word} ({exampleCounts[word] || 0} examples)\n                <button \n                  onClick={() => handleRecordExample(word)}\n                  disabled={isRecording || isTraining}\n                >\n                  {isRecording && currentWord === word ? 'Recording...' : 'Record Example'}\n                </button>\n              </li>\n            ))}\n          </ul>\n        )}\n      </div>\n      \n      <div className=\"training\">\n        <button \n          onClick={handleTrain}\n          disabled={customWords.length === 0 || isRecording || isTraining}\n        >\n          {isTraining ? 'Training...' : 'Train Model'}\n        </button>\n        \n        {isTraining && (\n          <div className=\"progress-bar\">\n            <div \n              className=\"progress\" \n              style={{ width: `${trainingProgress * 100}%` }}\n            />\n            <span>{Math.round(trainingProgress * 100)}%</span>\n          </div>\n        )}\n      </div>\n    </div>\n  );\n};\n\nexport default ModelTrainingComponent;\n"})}),"\n",(0,i.jsx)(n.h2,{id:"leistungsoptimierung",children:"Leistungsoptimierung"}),"\n",(0,i.jsx)(n.h3,{id:"modellquantisierung",children:"Modellquantisierung"}),"\n",(0,i.jsx)(n.p,{children:"F\xfcr kleinere Modellgr\xf6\xdfen und schnellere Inferenz k\xf6nnen Sie quantisierte Modelle verwenden:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// In ModelManager.ts\npublic async loadQuantizedModel(name: string): Promise<tf.LayersModel | null> {\n  const modelInfo = this.models.get(name);\n  if (!modelInfo) {\n    console.error(`Model \"${name}\" is not registered`);\n    return null;\n  }\n  \n  try {\n    // Lade das quantisierte Modell\n    const quantizedUrl = modelInfo.url.replace('model.json', 'model-quantized.json');\n    const model = await tf.loadLayersModel(quantizedUrl);\n    this.loadedModels.set(name, model);\n    return model;\n  } catch (error) {\n    console.error(`Failed to load quantized model \"${name}\":`, error);\n    \n    // Fallback auf nicht-quantisiertes Modell\n    return this.loadModel(name);\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"webgl-beschleunigung",children:"WebGL-Beschleunigung"}),"\n",(0,i.jsx)(n.p,{children:"F\xfcr bessere Leistung auf Ger\xe4ten mit GPU:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// In TensorFlowRecognitionEngine.ts\nprivate async optimizeForDevice() {\n  await tf.ready();\n  \n  // Pr\xfcfe, ob WebGL verf\xfcgbar ist\n  if (tf.ENV.flagRegistry.HAS_WEBGL) {\n    await tf.setBackend('webgl');\n    \n    // Konfiguriere WebGL f\xfcr bessere Leistung\n    const gl = await tf.backend().getGPGPUContext().gl;\n    if (gl) {\n      // Deaktiviere Tiefentest und Stencil f\xfcr bessere Leistung\n      gl.disable(gl.DEPTH_TEST);\n      gl.disable(gl.STENCIL_TEST);\n      gl.disable(gl.BLEND);\n      gl.disable(gl.DITHER);\n      gl.disable(gl.POLYGON_OFFSET_FILL);\n      gl.disable(gl.SAMPLE_COVERAGE);\n      gl.disable(gl.SAMPLE_ALPHA_TO_COVERAGE);\n    }\n  } else if (tf.ENV.flagRegistry.HAS_WASM) {\n    // Fallback auf WASM, wenn WebGL nicht verf\xfcgbar ist\n    await tf.setBackend('wasm');\n  } else {\n    // Fallback auf CPU\n    await tf.setBackend('cpu');\n  }\n  \n  console.log('TensorFlow.js backend:', tf.getBackend());\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"lazy-loading",children:"Lazy Loading"}),"\n",(0,i.jsx)(n.p,{children:"F\xfcr eine bessere Startzeit k\xf6nnen Sie TensorFlow.js und die Modelle lazy laden:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-tsx",children:"// src/App.tsx\nimport React, { lazy, Suspense, useState } from 'react';\n\n// Lazy-Laden der TensorFlow-basierten Sprachsteuerung\nconst TensorFlowVoiceControl = lazy(() => import('./voice-control/TensorFlowVoiceControl'));\n\nfunction App() {\n  const [useTensorFlow, setUseTensorFlow] = useState(false);\n\n  return (\n    <div className=\"app\">\n      <button onClick={() => setUseTensorFlow(!useTensorFlow)}>\n        {useTensorFlow ? 'Deaktivieren' : 'Aktivieren'} TensorFlow Sprachsteuerung\n      </button>\n\n      {useTensorFlow && (\n        <Suspense fallback={<div>Lade TensorFlow.js...</div>}>\n          <TensorFlowVoiceControl>\n            <YourApp />\n          </TensorFlowVoiceControl>\n        </Suspense>\n      )}\n    </div>\n  );\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"offline-unterst\xfctzung",children:"Offline-Unterst\xfctzung"}),"\n",(0,i.jsx)(n.p,{children:"F\xfcr vollst\xe4ndige Offline-Unterst\xfctzung k\xf6nnen Sie die Modelle im Service Worker cachen:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// src/service-worker.js\nconst CACHE_NAME = 'smolitux-voice-models-v1';\nconst MODEL_URLS = [\n  '/models/speech/general-de/model.json',\n  '/models/speech/general-de/weights.bin',\n  '/models/speech/general-en/model.json',\n  '/models/speech/general-en/weights.bin'\n];\n\nself.addEventListener('install', (event) => {\n  event.waitUntil(\n    caches.open(CACHE_NAME)\n      .then((cache) => {\n        return cache.addAll(MODEL_URLS);\n      })\n  );\n});\n\nself.addEventListener('fetch', (event) => {\n  // Pr\xfcfe, ob die Anfrage ein Modell betrifft\n  if (MODEL_URLS.some(url => event.request.url.includes(url))) {\n    event.respondWith(\n      caches.match(event.request)\n        .then((response) => {\n          return response || fetch(event.request);\n        })\n    );\n  }\n});\n"})}),"\n",(0,i.jsx)(n.h2,{id:"mehrsprachige-unterst\xfctzung",children:"Mehrsprachige Unterst\xfctzung"}),"\n",(0,i.jsx)(n.p,{children:"F\xfcr mehrsprachige Unterst\xfctzung k\xf6nnen Sie verschiedene Modelle f\xfcr verschiedene Sprachen laden:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/MultilingualVoiceControl.tsx\nimport React, { useState, useEffect } from 'react';\nimport { VoiceControlProvider } from './VoiceControlProvider';\nimport { ModelManager } from './models/ModelManager';\n\ninterface MultilingualVoiceControlProps {\n  children: React.ReactNode;\n  language?: string;\n}\n\nconst MultilingualVoiceControl: React.FC<MultilingualVoiceControlProps> = ({\n  children,\n  language = navigator.language\n}) => {\n  const [modelManager] = useState(() => new ModelManager());\n  const [engineType, setEngineType] = useState<'webSpeech' | 'tensorFlow'>('webSpeech');\n  const [modelName, setModelName] = useState<string | null>(null);\n  \n  useEffect(() => {\n    // W\xe4hle das passende Modell basierend auf der Sprache\n    const models = modelManager.getModelsByLanguage(language);\n    \n    if (models.length > 0) {\n      setModelName(models[0].name);\n      setEngineType('tensorFlow');\n    } else {\n      // Fallback auf Web Speech API, wenn kein passendes Modell gefunden wurde\n      setModelName(null);\n      setEngineType('webSpeech');\n    }\n  }, [language, modelManager]);\n  \n  return (\n    <VoiceControlProvider \n      engineType={engineType}\n      language={language}\n      tensorFlowOptions={modelName ? { customModelName: modelName } : undefined}\n    >\n      {children}\n    </VoiceControlProvider>\n  );\n};\n\nexport default MultilingualVoiceControl;\n"})}),"\n",(0,i.jsx)(n.h2,{id:"erweiterte-funktionen",children:"Erweiterte Funktionen"}),"\n",(0,i.jsx)(n.h3,{id:"kontinuierliche-spracherkennung",children:"Kontinuierliche Spracherkennung"}),"\n",(0,i.jsx)(n.p,{children:"F\xfcr eine kontinuierliche Spracherkennung ohne explizites Starten und Stoppen:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// In TensorFlowRecognitionEngine.ts\nprivate setupContinuousRecognition() {\n  // Starte die Erkennung automatisch\n  this.start();\n  \n  // Implementiere eine Aktivierungswort-Erkennung\n  let isActivated = false;\n  const activationWord = 'hey smolitux';\n  \n  // \xdcberschreibe die onResult-Methode\n  const originalOnResult = this.onResult;\n  this.onResult = (text) => {\n    const lowerText = text.toLowerCase();\n    \n    if (!isActivated) {\n      // Pr\xfcfe auf Aktivierungswort\n      if (lowerText === activationWord) {\n        isActivated = true;\n        // Gib visuelles/akustisches Feedback\n        console.log('Aktiviert!');\n        \n        // Deaktiviere nach 10 Sekunden automatisch\n        setTimeout(() => {\n          isActivated = false;\n          console.log('Deaktiviert (Timeout)');\n        }, 10000);\n      }\n    } else {\n      // Wenn aktiviert, leite den Text an die urspr\xfcngliche onResult-Methode weiter\n      originalOnResult(text);\n      \n      // Deaktiviere nach bestimmten Befehlen\n      if (lowerText === 'beenden' || lowerText === 'stop listening') {\n        isActivated = false;\n        console.log('Deaktiviert (Befehl)');\n      }\n    }\n  };\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"sprachsynthese-f\xfcr-feedback",children:"Sprachsynthese f\xfcr Feedback"}),"\n",(0,i.jsx)(n.p,{children:"F\xfcr akustisches Feedback k\xf6nnen Sie die Web Speech API f\xfcr Sprachsynthese verwenden:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/FeedbackManager.ts\nexport class FeedbackManager {\n  private audioContext: AudioContext | null = null;\n  private speechSynthesis: SpeechSynthesis | null = null;\n  private useSpeechFeedback: boolean;\n  \n  constructor(useSpeechFeedback = false) {\n    this.useSpeechFeedback = useSpeechFeedback;\n    \n    // Initialisiere Web Audio API\n    if (typeof window !== 'undefined') {\n      document.addEventListener('click', () => {\n        if (!this.audioContext) {\n          this.audioContext = new (window.AudioContext || window.webkitAudioContext)();\n        }\n      }, { once: true });\n    }\n    \n    // Initialisiere Speech Synthesis\n    if (typeof window !== 'undefined' && 'speechSynthesis' in window) {\n      this.speechSynthesis = window.speechSynthesis;\n    }\n  }\n  \n  provideFeedback(type: 'start' | 'stop' | 'command', command?: string) {\n    // Visuelles Feedback\n    this.provideVisualFeedback(type, command);\n    \n    // Akustisches Feedback\n    this.provideAudioFeedback(type);\n    \n    // Sprachfeedback\n    if (this.useSpeechFeedback) {\n      this.provideSpeechFeedback(type, command);\n    }\n  }\n  \n  // ... andere Methoden ...\n  \n  private provideSpeechFeedback(type: 'start' | 'stop' | 'command', command?: string) {\n    if (!this.speechSynthesis) return;\n    \n    let text = '';\n    \n    switch (type) {\n      case 'start':\n        text = 'Spracherkennung aktiviert';\n        break;\n      case 'stop':\n        text = 'Spracherkennung deaktiviert';\n        break;\n      case 'command':\n        text = `Befehl erkannt: ${command}`;\n        break;\n    }\n    \n    if (text) {\n      const utterance = new SpeechSynthesisUtterance(text);\n      utterance.lang = 'de-DE';\n      utterance.volume = 0.5;\n      utterance.rate = 1.0;\n      \n      this.speechSynthesis.speak(utterance);\n    }\n  }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"fehlerbehebung",children:"Fehlerbehebung"}),"\n",(0,i.jsx)(n.h3,{id:"h\xe4ufige-probleme-und-l\xf6sungen",children:"H\xe4ufige Probleme und L\xf6sungen"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": TensorFlow.js l\xe4dt nicht oder verursacht Fehler\n",(0,i.jsx)(n.strong,{children:"L\xf6sung"}),": Pr\xfcfen Sie die Browser-Kompatibilit\xe4t und verwenden Sie Polyfills f\xfcr \xe4ltere Browser"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// Polyfill f\xfcr \xe4ltere Browser\nimport '@tensorflow/tfjs-backend-cpu';\nimport '@tensorflow/tfjs-backend-webgl';\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Hohe CPU/GPU-Auslastung\n",(0,i.jsx)(n.strong,{children:"L\xf6sung"}),": Verwenden Sie WebWorker und optimieren Sie die Modellparameter"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// Reduzieren Sie die Abtastrate\nconst options = {\n  overlapFactor: 0.25, // Weniger \xdcberlappung = weniger Berechnungen\n  suppressionTimeMillis: 200 // L\xe4ngere Unterdr\xfcckungszeit = weniger Erkennungen\n};\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Niedrige Erkennungsgenauigkeit\n",(0,i.jsx)(n.strong,{children:"L\xf6sung"}),": Passen Sie die Schwellenwerte an und trainieren Sie benutzerdefinierte Modelle"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// Erh\xf6hen Sie den Schwellenwert f\xfcr h\xf6here Pr\xe4zision\nconst options = {\n  scoreThreshold: 0.85, // H\xf6herer Wert = h\xf6here Pr\xe4zision, aber weniger Erkennungen\n};\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Modelle werden nicht geladen\n",(0,i.jsx)(n.strong,{children:"L\xf6sung"}),": \xdcberpr\xfcfen Sie die CORS-Einstellungen und verwenden Sie lokale Modelle"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// Verwenden Sie lokale Modelle\nconst modelManager = new ModelManager();\nmodelManager.registerModel({\n  name: 'local-model',\n  url: '/models/speech/local-model/model.json',\n  // ...\n});\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"beispiele",children:"Beispiele"}),"\n",(0,i.jsx)(n.h3,{id:"grundlegende-verwendung",children:"Grundlegende Verwendung"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-tsx",children:"import React from 'react';\nimport { VoiceControlProvider } from './voice-control';\nimport { VoiceButton, VoiceInput } from './components/voice';\n\nfunction App() {\n  return (\n    <VoiceControlProvider engineType=\"tensorFlow\">\n      <div className=\"app\">\n        <h1>TensorFlow.js Sprachsteuerung</h1>\n        \n        <VoiceButton>Klick mich</VoiceButton>\n        \n        <VoiceInput \n          placeholder=\"Sprich, um Text einzugeben\"\n          voiceCommands={['eingabe', 'l\xf6schen']}\n        />\n      </div>\n    </VoiceControlProvider>\n  );\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"erweiterte-verwendung-mit-benutzerdefinierten-modellen",children:"Erweiterte Verwendung mit benutzerdefinierten Modellen"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-tsx",children:"import React, { useState, useEffect } from 'react';\nimport { VoiceControlProvider } from './voice-control';\nimport { ModelManager } from './voice-control/models/ModelManager';\nimport { VoiceButton, VoiceInput } from './components/voice';\n\nfunction App() {\n  const [modelManager] = useState(() => new ModelManager());\n  const [availableModels, setAvailableModels] = useState<string[]>([]);\n  const [selectedModel, setSelectedModel] = useState<string>('');\n  \n  useEffect(() => {\n    // Lade verf\xfcgbare Modelle\n    const models = modelManager.getAvailableModels();\n    setAvailableModels(models.map(model => model.name));\n    \n    // W\xe4hle das erste Modell als Standard\n    if (models.length > 0) {\n      setSelectedModel(models[0].name);\n    }\n  }, [modelManager]);\n  \n  return (\n    <div className=\"app\">\n      <div className=\"model-selector\">\n        <label>\n          Sprachmodell:\n          <select \n            value={selectedModel}\n            onChange={(e) => setSelectedModel(e.target.value)}\n          >\n            {availableModels.map(model => (\n              <option key={model} value={model}>{model}</option>\n            ))}\n          </select>\n        </label>\n      </div>\n      \n      {selectedModel && (\n        <VoiceControlProvider \n          engineType=\"tensorFlow\"\n          tensorFlowOptions={{ customModelName: selectedModel }}\n        >\n          <h1>TensorFlow.js Sprachsteuerung</h1>\n          \n          <VoiceButton>Klick mich</VoiceButton>\n          \n          <VoiceInput \n            placeholder=\"Sprich, um Text einzugeben\"\n            voiceCommands={['eingabe', 'l\xf6schen']}\n          />\n        </VoiceControlProvider>\n      )}\n    </div>\n  );\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"vollst\xe4ndiges-beispiel-mit-modelltraining",children:"Vollst\xe4ndiges Beispiel mit Modelltraining"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-tsx",children:"import React, { useState } from 'react';\nimport { VoiceControlProvider } from './voice-control';\nimport ModelTrainingComponent from './components/ModelTrainingComponent';\nimport { VoiceButton, VoiceInput } from './components/voice';\n\nfunction App() {\n  const [showTraining, setShowTraining] = useState(false);\n  const [useCustomModel, setUseCustomModel] = useState(false);\n  \n  return (\n    <div className=\"app\">\n      <div className=\"controls\">\n        <button onClick={() => setShowTraining(!showTraining)}>\n          {showTraining ? 'Anwendung anzeigen' : 'Modelltraining anzeigen'}\n        </button>\n        \n        <label>\n          <input \n            type=\"checkbox\" \n            checked={useCustomModel} \n            onChange={(e) => setUseCustomModel(e.target.checked)} \n          />\n          Benutzerdefiniertes Modell verwenden\n        </label>\n      </div>\n      \n      {showTraining ? (\n        <ModelTrainingComponent />\n      ) : (\n        <VoiceControlProvider \n          engineType=\"tensorFlow\"\n          tensorFlowOptions={\n            useCustomModel \n              ? { customModelUrl: 'indexeddb://my-custom-model' } \n              : undefined\n          }\n        >\n          <h1>TensorFlow.js Sprachsteuerung</h1>\n          \n          <VoiceButton>Klick mich</VoiceButton>\n          \n          <VoiceInput \n            placeholder=\"Sprich, um Text einzugeben\"\n            voiceCommands={['eingabe', 'l\xf6schen']}\n          />\n        </VoiceControlProvider>\n      )}\n    </div>\n  );\n}\n"})}),"\n",(0,i.jsx)(n.p,{children:"Diese Dokumentation bietet eine umfassende Anleitung zur Integration von TensorFlow.js in die Sprachsteuerungsfunktionalit\xe4t der Smolitux-UI-Bibliothek. Durch die Verwendung von TensorFlow.js k\xf6nnen Sie eine robuste, offline-f\xe4hige Spracherkennung implementieren, die in allen modernen Browsern konsistent funktioniert."})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>l});var o=r(6540);const i={},t=o.createContext(i);function s(e){const n=o.useContext(t);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);