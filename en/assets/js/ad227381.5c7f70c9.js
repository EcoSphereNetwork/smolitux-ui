"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3179],{4707:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>s,metadata:()=>r,toc:()=>a});const r=JSON.parse('{"id":"features/voice-control/voice-control-architecture","title":"Sprachsteuerungsarchitektur f\xfcr Smolitux-UI","description":"\xdcbersicht","source":"@site/docs/features/voice-control/voice-control-architecture.md","sourceDirName":"features/voice-control","slug":"/features/voice-control/voice-control-architecture","permalink":"/smolitux-ui/en/docs/features/voice-control/voice-control-architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/EcoSphereNetwork/smolitux-ui/tree/main/docs/docs/features/voice-control/voice-control-architecture.md","tags":[],"version":"current","frontMatter":{},"sidebar":"wikiSidebar","previous":{"title":"TensorFlow.js-Integration f\xfcr Sprachsteuerung","permalink":"/smolitux-ui/en/docs/features/voice-control/tensorflow-integration"},"next":{"title":"Verbesserungsplan: Button-Komponente","permalink":"/smolitux-ui/en/docs/improvement-plan/button-component"}}');var t=i(4848),o=i(8453);const s={},l="Sprachsteuerungsarchitektur f\xfcr Smolitux-UI",c={},a=[{value:"\xdcbersicht",id:"\xfcbersicht",level:2},{value:"Architektur\xfcbersicht",id:"architektur\xfcbersicht",level:2},{value:"Hauptkomponenten",id:"hauptkomponenten",level:3},{value:"Technologieauswahl",id:"technologieauswahl",level:2},{value:"1. Web Speech API",id:"1-web-speech-api",level:3},{value:"2. TensorFlow.js",id:"2-tensorflowjs",level:3},{value:"3. Externe Dienste",id:"3-externe-dienste",level:3},{value:"Implementierungsdetails",id:"implementierungsdetails",level:2},{value:"VoiceControlProvider",id:"voicecontrolprovider",level:3},{value:"VoiceControlManager",id:"voicecontrolmanager",level:3},{value:"Komponenten-Integration (HOC-Beispiel)",id:"komponenten-integration-hoc-beispiel",level:3},{value:"Beispiel: Sprachgesteuerte Button-Komponente",id:"beispiel-sprachgesteuerte-button-komponente",level:3},{value:"TensorFlow.js Integration",id:"tensorflowjs-integration",level:2},{value:"TensorFlow Recognition Engine",id:"tensorflow-recognition-engine",level:3},{value:"Anpassung und Erweiterung",id:"anpassung-und-erweiterung",level:2},{value:"Benutzerdefinierte Sprachbefehle",id:"benutzerdefinierte-sprachbefehle",level:3},{value:"Mehrsprachige Unterst\xfctzung",id:"mehrsprachige-unterst\xfctzung",level:3},{value:"Barrierefreiheit",id:"barrierefreiheit",level:3},{value:"Leistungsoptimierung",id:"leistungsoptimierung",level:2},{value:"Lazy Loading",id:"lazy-loading",level:3},{value:"Modelloptimierung",id:"modelloptimierung",level:3},{value:"Sicherheit und Datenschutz",id:"sicherheit-und-datenschutz",level:2},{value:"Lokale Verarbeitung",id:"lokale-verarbeitung",level:3},{value:"Datenschutzkontrollen",id:"datenschutzkontrollen",level:3},{value:"Beispiele und Anwendungsf\xe4lle",id:"beispiele-und-anwendungsf\xe4lle",level:2},{value:"Grundlegende Verwendung",id:"grundlegende-verwendung",level:3},{value:"Komplexe Formulare",id:"komplexe-formulare",level:3},{value:"Diagramme und Datenvisualisierung",id:"diagramme-und-datenvisualisierung",level:3},{value:"Fehlerbehebung und Debugging",id:"fehlerbehebung-und-debugging",level:2},{value:"Debugging-Modus",id:"debugging-modus",level:3},{value:"H\xe4ufige Probleme und L\xf6sungen",id:"h\xe4ufige-probleme-und-l\xf6sungen",level:3},{value:"Roadmap und zuk\xfcnftige Erweiterungen",id:"roadmap-und-zuk\xfcnftige-erweiterungen",level:2},{value:"Geplante Funktionen",id:"geplante-funktionen",level:3},{value:"Schlussfolgerung",id:"schlussfolgerung",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"sprachsteuerungsarchitektur-f\xfcr-smolitux-ui",children:"Sprachsteuerungsarchitektur f\xfcr Smolitux-UI"})}),"\n",(0,t.jsx)(n.h2,{id:"\xfcbersicht",children:"\xdcbersicht"}),"\n",(0,t.jsx)(n.p,{children:"Die Sprachsteuerungsarchitektur f\xfcr Smolitux-UI erm\xf6glicht eine vollst\xe4ndige Steuerung aller UI-Komponenten durch Sprachbefehle. Diese Dokumentation beschreibt die Architektur, Implementierungsdetails und Integrationsrichtlinien f\xfcr die Sprachsteuerungsfunktionalit\xe4t."}),"\n",(0,t.jsx)(n.h2,{id:"architektur\xfcbersicht",children:"Architektur\xfcbersicht"}),"\n",(0,t.jsx)(n.p,{children:"Die Sprachsteuerungsarchitektur besteht aus mehreren Schichten:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Smolitux-UI Komponenten                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502   Button    \u2502  \u2502    Input    \u2502  \u2502  Andere Komponenten \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                VoiceControlProvider (Context)               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    VoiceControlManager                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Recognition \u2502  \u2502  Command    \u2502  \u2502     Feedback        \u2502  \u2502\n\u2502  \u2502   Engine    \u2502  \u2502  Processor  \u2502  \u2502     Manager         \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Speech Recognition API                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Web Speech  \u2502  \u2502 TensorFlow  \u2502  \u2502 Externe Dienste     \u2502  \u2502\n\u2502  \u2502     API     \u2502  \u2502     JS      \u2502  \u2502 (Google, Azure)     \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(n.h3,{id:"hauptkomponenten",children:"Hauptkomponenten"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"VoiceControlProvider"}),": Ein React Context Provider, der die Sprachsteuerungsfunktionalit\xe4t f\xfcr alle Komponenten bereitstellt."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"VoiceControlManager"}),": Verwaltet die Spracherkennung, Befehlsverarbeitung und Feedback."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Recognition Engine"}),": Verarbeitet Audioeingaben und konvertiert sie in Text."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Command Processor"}),": Interpretiert erkannte Texte und ordnet sie Komponentenaktionen zu."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Feedback Manager"}),": Bietet akustisches und visuelles Feedback f\xfcr Benutzerinteraktionen."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Speech Recognition API"}),": Abstraktionsschicht f\xfcr verschiedene Spracherkennungs-Backends."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Web Speech API"}),": Browserbasierte Spracherkennung."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"TensorFlow.js"}),": Lokale Spracherkennungsmodelle."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Externe Dienste"}),": Integration mit Cloud-basierten Spracherkennungsdiensten."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Komponenten-Integration"}),": Jede Smolitux-UI-Komponente wird mit Sprachsteuerungsfunktionen erweitert."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"technologieauswahl",children:"Technologieauswahl"}),"\n",(0,t.jsx)(n.p,{children:"Die Sprachsteuerungsarchitektur unterst\xfctzt mehrere Technologien f\xfcr die Spracherkennung:"}),"\n",(0,t.jsx)(n.h3,{id:"1-web-speech-api",children:"1. Web Speech API"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Vorteile"}),": Nativ im Browser, keine zus\xe4tzlichen Abh\xe4ngigkeiten, einfache Integration"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Nachteile"}),": Browserunterst\xfctzung variiert, ben\xf6tigt Internetverbindung f\xfcr einige Implementierungen"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Verwendung"}),": Standard-Fallback und f\xfcr einfache Anwendungsf\xe4lle"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2-tensorflowjs",children:"2. TensorFlow.js"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Vorteile"}),": Lokale Verarbeitung, funktioniert offline, anpassbare Modelle"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Nachteile"}),": Gr\xf6\xdfere Paketgr\xf6\xdfe, h\xf6here CPU/GPU-Anforderungen"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Verwendung"}),": F\xfcr Anwendungen, die bereits TensorFlow verwenden oder erweiterte Spracherkennung ben\xf6tigen"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"3-externe-dienste",children:"3. Externe Dienste"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Vorteile"}),": Hohe Genauigkeit, mehrsprachige Unterst\xfctzung, kontinuierliche Verbesserungen"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Nachteile"}),": Kostenpflichtig, ben\xf6tigt Internetverbindung, Datenschutzbedenken"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Verwendung"}),": F\xfcr Produktionsanwendungen mit hohen Anforderungen an Genauigkeit"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"implementierungsdetails",children:"Implementierungsdetails"}),"\n",(0,t.jsx)(n.h3,{id:"voicecontrolprovider",children:"VoiceControlProvider"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import React, { createContext, useContext, useState, useEffect } from 'react';\nimport { VoiceControlManager } from './VoiceControlManager';\n\ninterface VoiceControlContextType {\n  isListening: boolean;\n  startListening: () => void;\n  stopListening: () => void;\n  recognizedText: string;\n  lastCommand: string;\n  targetComponent: string | null;\n  registerComponent: (id: string, commands: string[]) => void;\n  unregisterComponent: (id: string) => void;\n}\n\nconst VoiceControlContext = createContext<VoiceControlContextType | undefined>(undefined);\n\nexport const VoiceControlProvider: React.FC = ({ children }) => {\n  const [manager] = useState(() => new VoiceControlManager());\n  const [isListening, setIsListening] = useState(false);\n  const [recognizedText, setRecognizedText] = useState('');\n  const [lastCommand, setLastCommand] = useState('');\n  const [targetComponent, setTargetComponent] = useState<string | null>(null);\n\n  useEffect(() => {\n    manager.onRecognitionResult = (text) => {\n      setRecognizedText(text);\n    };\n\n    manager.onCommandRecognized = (command, target) => {\n      setLastCommand(command);\n      setTargetComponent(target);\n    };\n\n    manager.onListeningStateChanged = (listening) => {\n      setIsListening(listening);\n    };\n\n    return () => {\n      manager.cleanup();\n    };\n  }, [manager]);\n\n  const startListening = () => {\n    manager.startListening();\n  };\n\n  const stopListening = () => {\n    manager.stopListening();\n  };\n\n  const registerComponent = (id: string, commands: string[]) => {\n    manager.registerComponent(id, commands);\n  };\n\n  const unregisterComponent = (id: string) => {\n    manager.unregisterComponent(id);\n  };\n\n  return (\n    <VoiceControlContext.Provider\n      value={{\n        isListening,\n        startListening,\n        stopListening,\n        recognizedText,\n        lastCommand,\n        targetComponent,\n        registerComponent,\n        unregisterComponent,\n      }}\n    >\n      {children}\n    </VoiceControlContext.Provider>\n  );\n};\n\nexport const useVoiceControl = () => {\n  const context = useContext(VoiceControlContext);\n  if (context === undefined) {\n    throw new Error('useVoiceControl must be used within a VoiceControlProvider');\n  }\n  return context;\n};\n"})}),"\n",(0,t.jsx)(n.h3,{id:"voicecontrolmanager",children:"VoiceControlManager"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import { RecognitionEngine } from './engines/RecognitionEngine';\nimport { WebSpeechRecognitionEngine } from './engines/WebSpeechRecognitionEngine';\nimport { TensorFlowRecognitionEngine } from './engines/TensorFlowRecognitionEngine';\nimport { CommandProcessor } from './CommandProcessor';\nimport { FeedbackManager } from './FeedbackManager';\n\nexport class VoiceControlManager {\n  private recognitionEngine: RecognitionEngine;\n  private commandProcessor: CommandProcessor;\n  private feedbackManager: FeedbackManager;\n  private registeredComponents: Map<string, string[]> = new Map();\n\n  public onRecognitionResult: (text: string) => void = () => {};\n  public onCommandRecognized: (command: string, target: string) => void = () => {};\n  public onListeningStateChanged: (isListening: boolean) => void = () => {};\n\n  constructor(engineType: 'webSpeech' | 'tensorFlow' | 'external' = 'webSpeech') {\n    // Initialisiere die entsprechende Engine basierend auf dem Typ\n    switch (engineType) {\n      case 'tensorFlow':\n        this.recognitionEngine = new TensorFlowRecognitionEngine();\n        break;\n      case 'external':\n        // Implementierung f\xfcr externe Dienste\n        this.recognitionEngine = new WebSpeechRecognitionEngine(); // Fallback\n        break;\n      case 'webSpeech':\n      default:\n        this.recognitionEngine = new WebSpeechRecognitionEngine();\n        break;\n    }\n\n    this.commandProcessor = new CommandProcessor();\n    this.feedbackManager = new FeedbackManager();\n\n    this.setupEventListeners();\n  }\n\n  private setupEventListeners() {\n    this.recognitionEngine.onResult = (text) => {\n      this.onRecognitionResult(text);\n      const { command, targetId } = this.commandProcessor.processCommand(\n        text,\n        this.registeredComponents\n      );\n      \n      if (command && targetId) {\n        this.onCommandRecognized(command, targetId);\n        this.feedbackManager.provideFeedback('command', command);\n      }\n    };\n\n    this.recognitionEngine.onStateChange = (isListening) => {\n      this.onListeningStateChanged(isListening);\n    };\n  }\n\n  public startListening() {\n    this.recognitionEngine.start();\n    this.feedbackManager.provideFeedback('start');\n  }\n\n  public stopListening() {\n    this.recognitionEngine.stop();\n    this.feedbackManager.provideFeedback('stop');\n  }\n\n  public registerComponent(id: string, commands: string[]) {\n    this.registeredComponents.set(id, commands);\n  }\n\n  public unregisterComponent(id: string) {\n    this.registeredComponents.delete(id);\n  }\n\n  public cleanup() {\n    this.recognitionEngine.cleanup();\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"komponenten-integration-hoc-beispiel",children:"Komponenten-Integration (HOC-Beispiel)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import React, { useEffect, useRef, useId } from 'react';\nimport { useVoiceControl } from './VoiceControlProvider';\n\nexport interface VoiceControlProps {\n  voiceCommands?: string[];\n  voiceEnabled?: boolean;\n  onVoiceCommand?: (command: string) => void;\n}\n\nexport function withVoiceControl<P extends object>(\n  Component: React.ComponentType<P>,\n  defaultCommands: string[] = []\n) {\n  return React.forwardRef<unknown, P & VoiceControlProps>((props, ref) => {\n    const {\n      voiceCommands = defaultCommands,\n      voiceEnabled = true,\n      onVoiceCommand,\n      ...rest\n    } = props;\n\n    const id = useId();\n    const { registerComponent, unregisterComponent, targetComponent, lastCommand } = useVoiceControl();\n    const componentRef = useRef<HTMLElement>(null);\n\n    useEffect(() => {\n      if (voiceEnabled && voiceCommands.length > 0) {\n        registerComponent(id, voiceCommands);\n      }\n\n      return () => {\n        if (voiceEnabled) {\n          unregisterComponent(id);\n        }\n      };\n    }, [id, registerComponent, unregisterComponent, voiceEnabled, voiceCommands]);\n\n    useEffect(() => {\n      if (targetComponent === id && lastCommand && onVoiceCommand) {\n        onVoiceCommand(lastCommand);\n      }\n    }, [id, lastCommand, onVoiceCommand, targetComponent]);\n\n    return <Component ref={ref || componentRef} {...(rest as P)} />;\n  });\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"beispiel-sprachgesteuerte-button-komponente",children:"Beispiel: Sprachgesteuerte Button-Komponente"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import React from 'react';\nimport { Button as BaseButton, ButtonProps } from '@smolitux/core';\nimport { withVoiceControl, VoiceControlProps } from '../voice-control';\n\nexport type VoiceButtonProps = ButtonProps & VoiceControlProps;\n\nconst VoiceButtonBase: React.FC<VoiceButtonProps> = ({ \n  onVoiceCommand, \n  onClick,\n  children,\n  ...props \n}) => {\n  const handleClick = (event: React.MouseEvent<HTMLButtonElement>) => {\n    if (onClick) {\n      onClick(event);\n    }\n  };\n\n  const handleVoiceCommand = (command: string) => {\n    if (command.toLowerCase() === 'klick' || command.toLowerCase() === 'click') {\n      // Simuliere einen Klick-Event\n      const buttonElement = document.getElementById(props.id || '');\n      if (buttonElement) {\n        buttonElement.click();\n      }\n    }\n\n    if (onVoiceCommand) {\n      onVoiceCommand(command);\n    }\n  };\n\n  return (\n    <BaseButton\n      onClick={handleClick}\n      onVoiceCommand={handleVoiceCommand}\n      {...props}\n    >\n      {children}\n    </BaseButton>\n  );\n};\n\nexport const VoiceButton = withVoiceControl(VoiceButtonBase, ['klick', 'click']);\n"})}),"\n",(0,t.jsx)(n.h2,{id:"tensorflowjs-integration",children:"TensorFlow.js Integration"}),"\n",(0,t.jsx)(n.p,{children:"F\xfcr Anwendungen, die bereits TensorFlow verwenden, bietet die Sprachsteuerungsarchitektur eine nahtlose Integration mit TensorFlow.js-basierten Spracherkennungsmodellen."}),"\n",(0,t.jsx)(n.h3,{id:"tensorflow-recognition-engine",children:"TensorFlow Recognition Engine"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import * as tf from '@tensorflow/tfjs';\nimport * as speech from '@tensorflow-models/speech-commands';\nimport { RecognitionEngine } from './RecognitionEngine';\n\nexport class TensorFlowRecognitionEngine implements RecognitionEngine {\n  private model: speech.SpeechCommandRecognizer | null = null;\n  private listening = false;\n  private commandVocabulary: string[] = [];\n\n  public onResult: (text: string) => void = () => {};\n  public onStateChange: (isListening: boolean) => void = () => {};\n\n  constructor() {\n    this.initModel();\n  }\n\n  private async initModel() {\n    // Lade das Modell\n    this.model = speech.create('BROWSER_FFT');\n    await this.model.ensureModelLoaded();\n    \n    // Hole verf\xfcgbare Befehle\n    this.commandVocabulary = this.model.wordLabels();\n    \n    // Konfiguriere das Modell\n    this.model.params().scoreThreshold = 0.75;\n  }\n\n  public async start() {\n    if (!this.model) {\n      await this.initModel();\n    }\n    \n    if (this.model && !this.listening) {\n      this.listening = true;\n      this.onStateChange(true);\n      \n      this.model.listen(\n        result => {\n          const scores = Array.from(result.scores);\n          const maxScore = Math.max(...scores);\n          const maxScoreIndex = scores.indexOf(maxScore);\n          \n          if (maxScore > this.model!.params().scoreThreshold) {\n            const recognizedCommand = this.commandVocabulary[maxScoreIndex];\n            this.onResult(recognizedCommand);\n          }\n        },\n        {\n          includeSpectrogram: false,\n          probabilityThreshold: 0.75,\n          overlapFactor: 0.5\n        }\n      );\n    }\n  }\n\n  public stop() {\n    if (this.model && this.listening) {\n      this.model.stopListening();\n      this.listening = false;\n      this.onStateChange(false);\n    }\n  }\n\n  public cleanup() {\n    this.stop();\n    if (this.model) {\n      this.model.stopListening();\n    }\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"anpassung-und-erweiterung",children:"Anpassung und Erweiterung"}),"\n",(0,t.jsx)(n.h3,{id:"benutzerdefinierte-sprachbefehle",children:"Benutzerdefinierte Sprachbefehle"}),"\n",(0,t.jsx)(n.p,{children:"Komponenten k\xf6nnen benutzerdefinierte Sprachbefehle registrieren:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"// Beispiel: Registrierung benutzerdefinierter Befehle f\xfcr eine Tabelle\n<VoiceTable\n  voiceCommands={[\n    'sortiere nach name',\n    'sortiere nach datum',\n    'gehe zur seite 2',\n    'zeige 50 eintr\xe4ge'\n  ]}\n  onVoiceCommand={(command) => {\n    if (command === 'sortiere nach name') {\n      // Implementiere Sortierung nach Name\n    } else if (command === 'sortiere nach datum') {\n      // Implementiere Sortierung nach Datum\n    }\n    // ...\n  }}\n/>\n"})}),"\n",(0,t.jsx)(n.h3,{id:"mehrsprachige-unterst\xfctzung",children:"Mehrsprachige Unterst\xfctzung"}),"\n",(0,t.jsx)(n.p,{children:"Die Sprachsteuerungsarchitektur unterst\xfctzt mehrere Sprachen:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:'<VoiceControlProvider language="de-DE">\n  <App />\n</VoiceControlProvider>\n'})}),"\n",(0,t.jsx)(n.h3,{id:"barrierefreiheit",children:"Barrierefreiheit"}),"\n",(0,t.jsx)(n.p,{children:"Die Sprachsteuerung verbessert die Barrierefreiheit durch:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"ARIA-Attribute f\xfcr Sprachsteuerungsfunktionen"}),"\n",(0,t.jsx)(n.li,{children:"Akustisches Feedback f\xfcr Benutzerinteraktionen"}),"\n",(0,t.jsx)(n.li,{children:"Visuelle Indikatoren f\xfcr den Spracherkennungsstatus"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"leistungsoptimierung",children:"Leistungsoptimierung"}),"\n",(0,t.jsx)(n.h3,{id:"lazy-loading",children:"Lazy Loading"}),"\n",(0,t.jsx)(n.p,{children:"F\xfcr Anwendungen, die die Paketgr\xf6\xdfe minimieren m\xfcssen, unterst\xfctzt die Architektur Lazy Loading:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import React, { lazy, Suspense } from 'react';\n\nconst VoiceControlProvider = lazy(() => import('./voice-control/VoiceControlProvider'));\n\nfunction App() {\n  return (\n    <Suspense fallback={<div>Loading voice control...</div>}>\n      <VoiceControlProvider>\n        <YourApp />\n      </VoiceControlProvider>\n    </Suspense>\n  );\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"modelloptimierung",children:"Modelloptimierung"}),"\n",(0,t.jsx)(n.p,{children:"F\xfcr TensorFlow.js-basierte Erkennung:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Verwendung quantisierter Modelle f\xfcr geringere Gr\xf6\xdfe"}),"\n",(0,t.jsx)(n.li,{children:"WebWorker f\xfcr Hintergrundverarbeitung"}),"\n",(0,t.jsx)(n.li,{children:"Selektives Laden von Sprachmodellen basierend auf der Benutzersprache"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"sicherheit-und-datenschutz",children:"Sicherheit und Datenschutz"}),"\n",(0,t.jsx)(n.h3,{id:"lokale-verarbeitung",children:"Lokale Verarbeitung"}),"\n",(0,t.jsx)(n.p,{children:"Die Architektur priorisiert lokale Verarbeitung, wenn m\xf6glich:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"TensorFlow.js-Modelle werden lokal ausgef\xfchrt"}),"\n",(0,t.jsx)(n.li,{children:"Web Speech API kann in einigen Browsern lokal funktionieren"}),"\n",(0,t.jsx)(n.li,{children:"Optionale Verwendung externer Dienste mit expliziter Benutzereinwilligung"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"datenschutzkontrollen",children:"Datenschutzkontrollen"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Klare Benutzerhinweise zur Audioaufnahme"}),"\n",(0,t.jsx)(n.li,{children:"Optionen zum Deaktivieren der Sprachsteuerung"}),"\n",(0,t.jsx)(n.li,{children:"Keine permanente Speicherung von Audioaufnahmen"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"beispiele-und-anwendungsf\xe4lle",children:"Beispiele und Anwendungsf\xe4lle"}),"\n",(0,t.jsx)(n.h3,{id:"grundlegende-verwendung",children:"Grundlegende Verwendung"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"import { VoiceControlProvider, VoiceButton, VoiceInput } from '@smolitux/voice-control';\n\nfunction MyApp() {\n  return (\n    <VoiceControlProvider>\n      <h1>Sprachgesteuerte Anwendung</h1>\n      \n      <VoiceButton>Klick mich</VoiceButton>\n      \n      <VoiceInput \n        placeholder=\"Sprich, um Text einzugeben\"\n        voiceCommands={['eingabe', 'l\xf6schen']}\n      />\n    </VoiceControlProvider>\n  );\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"komplexe-formulare",children:"Komplexe Formulare"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"<VoiceForm\n  voiceCommands={['formular absenden', 'formular zur\xfccksetzen']}\n  onVoiceCommand={(cmd) => {\n    if (cmd === 'formular absenden') {\n      // Formular absenden\n    }\n  }}\n>\n  <VoiceInput name=\"name\" voiceCommands={['name eingeben']} />\n  <VoiceSelect \n    name=\"kategorie\"\n    options={['Option 1', 'Option 2']}\n    voiceCommands={['kategorie ausw\xe4hlen', 'option 1 w\xe4hlen', 'option 2 w\xe4hlen']}\n  />\n  <VoiceButton type=\"submit\">Absenden</VoiceButton>\n</VoiceForm>\n"})}),"\n",(0,t.jsx)(n.h3,{id:"diagramme-und-datenvisualisierung",children:"Diagramme und Datenvisualisierung"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"<VoiceChart\n  data={chartData}\n  voiceCommands={[\n    'zoom in', \n    'zoom out', \n    'zeige details', \n    'vergleiche mit vorjahr'\n  ]}\n  onVoiceCommand={(cmd) => {\n    // Implementiere Diagrammaktionen basierend auf Sprachbefehlen\n  }}\n/>\n"})}),"\n",(0,t.jsx)(n.h2,{id:"fehlerbehebung-und-debugging",children:"Fehlerbehebung und Debugging"}),"\n",(0,t.jsx)(n.h3,{id:"debugging-modus",children:"Debugging-Modus"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-tsx",children:"<VoiceControlProvider debug={true}>\n  <App />\n</VoiceControlProvider>\n"})}),"\n",(0,t.jsx)(n.p,{children:"Im Debug-Modus werden folgende Informationen angezeigt:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Erkannter Text"}),"\n",(0,t.jsx)(n.li,{children:"Verarbeitete Befehle"}),"\n",(0,t.jsx)(n.li,{children:"Zielkomponenten"}),"\n",(0,t.jsx)(n.li,{children:"Erkennungsgenauigkeit"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"h\xe4ufige-probleme-und-l\xf6sungen",children:"H\xe4ufige Probleme und L\xf6sungen"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Problem"}),": Spracherkennung funktioniert nicht in allen Browsern\n",(0,t.jsx)(n.strong,{children:"L\xf6sung"}),": Implementiere Fallback-Mechanismen und Browser-Erkennung"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Problem"}),": Niedrige Erkennungsgenauigkeit\n",(0,t.jsx)(n.strong,{children:"L\xf6sung"}),": Passe Schwellenwerte an oder wechsle zu einem leistungsf\xe4higeren Backend"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Problem"}),": Hohe CPU-Auslastung bei TensorFlow.js\n",(0,t.jsx)(n.strong,{children:"L\xf6sung"}),": Verwende WebWorker und optimierte Modelle"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"roadmap-und-zuk\xfcnftige-erweiterungen",children:"Roadmap und zuk\xfcnftige Erweiterungen"}),"\n",(0,t.jsx)(n.h3,{id:"geplante-funktionen",children:"Geplante Funktionen"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Nat\xfcrliche Sprachverarbeitung"}),": Integration mit NLP-Bibliotheken f\xfcr kontextbezogenes Verst\xe4ndnis"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Benutzerdefinierte Wakewords"}),": Anpassbare Aktivierungsw\xf6rter f\xfcr die Spracherkennung"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sprachsynthese"}),": Text-to-Speech-Feedback f\xfcr verbesserte Barrierefreiheit"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Offline-Modelle"}),": Erweiterte Unterst\xfctzung f\xfcr vollst\xe4ndig offline Spracherkennung"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Gestenerkennung"}),": Kombination von Sprach- und Gestensteuerung"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"schlussfolgerung",children:"Schlussfolgerung"}),"\n",(0,t.jsx)(n.p,{children:"Die Sprachsteuerungsarchitektur f\xfcr Smolitux-UI bietet eine flexible, leistungsstarke und barrierefreie Methode zur Interaktion mit UI-Komponenten. Durch die Unterst\xfctzung mehrerer Backends, einschlie\xdflich TensorFlow.js, k\xf6nnen Entwickler die optimale L\xf6sung f\xfcr ihre spezifischen Anforderungen w\xe4hlen."})]})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>l});var r=i(6540);const t={},o=r.createContext(t);function s(e){const n=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);