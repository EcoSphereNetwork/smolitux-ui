"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9441],{8052:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"features/voice-control/implementation-guide","title":"Implementierungsleitfaden f\xfcr Sprachsteuerung in Smolitux-UI","description":"Dieser Leitfaden bietet detaillierte Anweisungen zur Implementierung der Sprachsteuerungsfunktionalit\xe4t in der Smolitux-UI-Bibliothek. Er richtet sich an Entwickler, die die Sprachsteuerung in ihre Komponenten integrieren m\xf6chten.","source":"@site/wiki/features/voice-control/implementation-guide.md","sourceDirName":"features/voice-control","slug":"/features/voice-control/implementation-guide","permalink":"/smolitux-ui/en/wiki/features/voice-control/implementation-guide","draft":false,"unlisted":false,"editUrl":"https://github.com/EcoSphereNetwork/smolitux-ui/tree/main/docs/wiki/wiki/features/voice-control/implementation-guide.md","tags":[],"version":"current","frontMatter":{},"sidebar":"guideSidebar","previous":{"title":"Sprachsteuerung: Komponenten-Integration","permalink":"/smolitux-ui/en/wiki/features/voice-control/component-integration"},"next":{"title":"Sprachgesteuerte Modale","permalink":"/smolitux-ui/en/wiki/features/voice-control/modal-integration"}}');var o=t(4848),r=t(8453);const s={},c="Implementierungsleitfaden f\xfcr Sprachsteuerung in Smolitux-UI",a={},l=[{value:"Inhaltsverzeichnis",id:"inhaltsverzeichnis",level:2},{value:"Voraussetzungen",id:"voraussetzungen",level:2},{value:"Abh\xe4ngigkeiten",id:"abh\xe4ngigkeiten",level:3},{value:"Projektstruktur",id:"projektstruktur",level:2},{value:"Schritt-f\xfcr-Schritt-Implementierung",id:"schritt-f\xfcr-schritt-implementierung",level:2},{value:"1. Erstellen der Basisschnittstellen",id:"1-erstellen-der-basisschnittstellen",level:3},{value:"2. Implementieren der Web Speech API Engine",id:"2-implementieren-der-web-speech-api-engine",level:3},{value:"3. Implementieren des Command Processors",id:"3-implementieren-des-command-processors",level:3},{value:"4. Implementieren des Feedback Managers",id:"4-implementieren-des-feedback-managers",level:3},{value:"5. Implementieren des VoiceControlManagers",id:"5-implementieren-des-voicecontrolmanagers",level:3},{value:"6. Implementieren des VoiceControlProviders",id:"6-implementieren-des-voicecontrolproviders",level:3},{value:"7. Implementieren des withVoiceControl HOC",id:"7-implementieren-des-withvoicecontrol-hoc",level:3},{value:"8. Erstellen der Exportdatei",id:"8-erstellen-der-exportdatei",level:3},{value:"Komponenten-Integration",id:"komponenten-integration",level:2},{value:"Beispiel: Sprachgesteuerter Button",id:"beispiel-sprachgesteuerter-button",level:3},{value:"Beispiel: Sprachgesteuertes Eingabefeld",id:"beispiel-sprachgesteuertes-eingabefeld",level:3},{value:"Beispiel: Sprachgesteuertes Auswahlfeld",id:"beispiel-sprachgesteuertes-auswahlfeld",level:3},{value:"TensorFlow.js-Integration",id:"tensorflowjs-integration",level:2},{value:"Anpassung des VoiceControlProviders f\xfcr TensorFlow.js",id:"anpassung-des-voicecontrolproviders-f\xfcr-tensorflowjs",level:3},{value:"Testen und Debugging",id:"testen-und-debugging",level:2},{value:"Unit-Tests f\xfcr die Sprachsteuerung",id:"unit-tests-f\xfcr-die-sprachsteuerung",level:3},{value:"Debugging-Tipps",id:"debugging-tipps",level:3},{value:"Leistungsoptimierung",id:"leistungsoptimierung",level:2},{value:"Lazy Loading der Sprachsteuerung",id:"lazy-loading-der-sprachsteuerung",level:3},{value:"Optimierung der TensorFlow.js-Modelle",id:"optimierung-der-tensorflowjs-modelle",level:3},{value:"Verwendung von WebWorkers",id:"verwendung-von-webworkers",level:3},{value:"Barrierefreiheit",id:"barrierefreiheit",level:2},{value:"ARIA-Attribute f\xfcr Sprachsteuerung",id:"aria-attribute-f\xfcr-sprachsteuerung",level:3},{value:"Tastaturunterst\xfctzung",id:"tastaturunterst\xfctzung",level:3},{value:"Mehrsprachige Unterst\xfctzung",id:"mehrsprachige-unterst\xfctzung",level:2},{value:"Sprachkonfiguration",id:"sprachkonfiguration",level:3},{value:"Lokalisierte Befehle",id:"lokalisierte-befehle",level:3},{value:"H\xe4ufig gestellte Fragen",id:"h\xe4ufig-gestellte-fragen",level:2},{value:"1. Wie kann ich die Spracherkennung in meiner Anwendung aktivieren?",id:"1-wie-kann-ich-die-spracherkennung-in-meiner-anwendung-aktivieren",level:3},{value:"2. Wie kann ich benutzerdefinierte Sprachbefehle f\xfcr eine Komponente definieren?",id:"2-wie-kann-ich-benutzerdefinierte-sprachbefehle-f\xfcr-eine-komponente-definieren",level:3},{value:"3. Wie kann ich zwischen verschiedenen Spracherkennungs-Backends wechseln?",id:"3-wie-kann-ich-zwischen-verschiedenen-spracherkennungs-backends-wechseln",level:3},{value:"4. Wie kann ich die Spracherkennung programmatisch starten und stoppen?",id:"4-wie-kann-ich-die-spracherkennung-programmatisch-starten-und-stoppen",level:3},{value:"5. Wie kann ich die Sprachsteuerung f\xfcr bestimmte Komponenten deaktivieren?",id:"5-wie-kann-ich-die-sprachsteuerung-f\xfcr-bestimmte-komponenten-deaktivieren",level:3},{value:"6. Wie kann ich die Erkennungsgenauigkeit verbessern?",id:"6-wie-kann-ich-die-erkennungsgenauigkeit-verbessern",level:3},{value:"7. Wie kann ich die Leistung der Sprachsteuerung optimieren?",id:"7-wie-kann-ich-die-leistung-der-sprachsteuerung-optimieren",level:3},{value:"8. Wie kann ich die Sprachsteuerung f\xfcr Barrierefreiheit optimieren?",id:"8-wie-kann-ich-die-sprachsteuerung-f\xfcr-barrierefreiheit-optimieren",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"implementierungsleitfaden-f\xfcr-sprachsteuerung-in-smolitux-ui",children:"Implementierungsleitfaden f\xfcr Sprachsteuerung in Smolitux-UI"})}),"\n",(0,o.jsx)(n.p,{children:"Dieser Leitfaden bietet detaillierte Anweisungen zur Implementierung der Sprachsteuerungsfunktionalit\xe4t in der Smolitux-UI-Bibliothek. Er richtet sich an Entwickler, die die Sprachsteuerung in ihre Komponenten integrieren m\xf6chten."}),"\n",(0,o.jsx)(n.h2,{id:"inhaltsverzeichnis",children:"Inhaltsverzeichnis"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"#voraussetzungen",children:"Voraussetzungen"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"#projektstruktur",children:"Projektstruktur"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"#schritt-f%C3%BCr-schritt-implementierung",children:"Schritt-f\xfcr-Schritt-Implementierung"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"#komponenten-integration",children:"Komponenten-Integration"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"#tensorflowjs-integration",children:"TensorFlow.js-Integration"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"#testen-und-debugging",children:"Testen und Debugging"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"#leistungsoptimierung",children:"Leistungsoptimierung"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"#barrierefreiheit",children:"Barrierefreiheit"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"#mehrsprachige-unterst%C3%BCtzung",children:"Mehrsprachige Unterst\xfctzung"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"#h%C3%A4ufig-gestellte-fragen",children:"H\xe4ufig gestellte Fragen"})}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"voraussetzungen",children:"Voraussetzungen"}),"\n",(0,o.jsx)(n.p,{children:"Bevor Sie mit der Implementierung beginnen, stellen Sie sicher, dass Sie folgende Voraussetzungen erf\xfcllen:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Node.js 14+ und npm/yarn"}),"\n",(0,o.jsx)(n.li,{children:"React 16.8+ (f\xfcr Hooks-Unterst\xfctzung)"}),"\n",(0,o.jsx)(n.li,{children:"TypeScript 4.0+ (empfohlen)"}),"\n",(0,o.jsx)(n.li,{children:"Grundlegende Kenntnisse der Web Speech API oder TensorFlow.js"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"abh\xe4ngigkeiten",children:"Abh\xe4ngigkeiten"}),"\n",(0,o.jsx)(n.p,{children:"F\xfcgen Sie die folgenden Abh\xe4ngigkeiten zu Ihrem Projekt hinzu:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# F\xfcr Web Speech API-basierte Implementierung\nnpm install --save @smolitux/voice-control\n\n# F\xfcr TensorFlow.js-basierte Implementierung\nnpm install --save @smolitux/voice-control @tensorflow/tfjs @tensorflow-models/speech-commands\n"})}),"\n",(0,o.jsx)(n.h2,{id:"projektstruktur",children:"Projektstruktur"}),"\n",(0,o.jsx)(n.p,{children:"Die empfohlene Projektstruktur f\xfcr die Sprachsteuerungsimplementierung ist wie folgt:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"src/\n\u251c\u2500\u2500 voice-control/\n\u2502   \u251c\u2500\u2500 engines/\n\u2502   \u2502   \u251c\u2500\u2500 RecognitionEngine.ts\n\u2502   \u2502   \u251c\u2500\u2500 WebSpeechRecognitionEngine.ts\n\u2502   \u2502   \u251c\u2500\u2500 TensorFlowRecognitionEngine.ts\n\u2502   \u2502   \u2514\u2500\u2500 ExternalServiceEngine.ts\n\u2502   \u251c\u2500\u2500 CommandProcessor.ts\n\u2502   \u251c\u2500\u2500 FeedbackManager.ts\n\u2502   \u251c\u2500\u2500 VoiceControlManager.ts\n\u2502   \u251c\u2500\u2500 VoiceControlProvider.tsx\n\u2502   \u251c\u2500\u2500 withVoiceControl.tsx\n\u2502   \u2514\u2500\u2500 index.ts\n\u251c\u2500\u2500 components/\n\u2502   \u251c\u2500\u2500 voice/\n\u2502   \u2502   \u251c\u2500\u2500 VoiceButton.tsx\n\u2502   \u2502   \u251c\u2500\u2500 VoiceInput.tsx\n\u2502   \u2502   \u251c\u2500\u2500 VoiceSelect.tsx\n\u2502   \u2502   \u2514\u2500\u2500 ... (weitere sprachgesteuerte Komponenten)\n\u2502   \u2514\u2500\u2500 ... (andere Komponenten)\n\u2514\u2500\u2500 ... (andere Projektdateien)\n"})}),"\n",(0,o.jsx)(n.h2,{id:"schritt-f\xfcr-schritt-implementierung",children:"Schritt-f\xfcr-Schritt-Implementierung"}),"\n",(0,o.jsx)(n.h3,{id:"1-erstellen-der-basisschnittstellen",children:"1. Erstellen der Basisschnittstellen"}),"\n",(0,o.jsx)(n.p,{children:"Erstellen Sie zun\xe4chst die grundlegenden Schnittstellen f\xfcr die Spracherkennungs-Engines:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/engines/RecognitionEngine.ts\nexport interface RecognitionEngine {\n  onResult: (text: string) => void;\n  onStateChange: (isListening: boolean) => void;\n  start: () => void;\n  stop: () => void;\n  cleanup: () => void;\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"2-implementieren-der-web-speech-api-engine",children:"2. Implementieren der Web Speech API Engine"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/engines/WebSpeechRecognitionEngine.ts\nimport { RecognitionEngine } from './RecognitionEngine';\n\nexport class WebSpeechRecognitionEngine implements RecognitionEngine {\n  private recognition: SpeechRecognition | null = null;\n  private listening = false;\n\n  public onResult: (text: string) => void = () => {};\n  public onStateChange: (isListening: boolean) => void = () => {};\n\n  constructor(language = 'de-DE') {\n    if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {\n      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n      this.recognition = new SpeechRecognition();\n      this.recognition.lang = language;\n      this.recognition.continuous = true;\n      this.recognition.interimResults = false;\n\n      this.setupEventListeners();\n    } else {\n      console.error('Speech recognition is not supported in this browser.');\n    }\n  }\n\n  private setupEventListeners() {\n    if (!this.recognition) return;\n\n    this.recognition.onresult = (event) => {\n      const last = event.results.length - 1;\n      const text = event.results[last][0].transcript;\n      this.onResult(text);\n    };\n\n    this.recognition.onstart = () => {\n      this.listening = true;\n      this.onStateChange(true);\n    };\n\n    this.recognition.onend = () => {\n      this.listening = false;\n      this.onStateChange(false);\n    };\n\n    this.recognition.onerror = (event) => {\n      console.error('Speech recognition error', event.error);\n      this.listening = false;\n      this.onStateChange(false);\n    };\n  }\n\n  public start() {\n    if (this.recognition && !this.listening) {\n      this.recognition.start();\n    }\n  }\n\n  public stop() {\n    if (this.recognition && this.listening) {\n      this.recognition.stop();\n    }\n  }\n\n  public cleanup() {\n    this.stop();\n    if (this.recognition) {\n      this.recognition.onresult = null;\n      this.recognition.onstart = null;\n      this.recognition.onend = null;\n      this.recognition.onerror = null;\n    }\n  }\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"3-implementieren-des-command-processors",children:"3. Implementieren des Command Processors"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/CommandProcessor.ts\nexport class CommandProcessor {\n  processCommand(\n    text: string,\n    registeredComponents: Map<string, string[]>\n  ): { command: string; targetId: string } | { command: null; targetId: null } {\n    const normalizedText = text.toLowerCase().trim();\n    \n    for (const [componentId, commands] of registeredComponents.entries()) {\n      for (const command of commands) {\n        if (normalizedText.includes(command.toLowerCase())) {\n          return { command, targetId: componentId };\n        }\n      }\n    }\n    \n    return { command: null, targetId: null };\n  }\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"4-implementieren-des-feedback-managers",children:"4. Implementieren des Feedback Managers"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/FeedbackManager.ts\nexport class FeedbackManager {\n  private audioContext: AudioContext | null = null;\n  \n  constructor() {\n    // Lazy-Initialisierung des AudioContext, um Browserrichtlinien zu erf\xfcllen\n    if (typeof window !== 'undefined') {\n      document.addEventListener('click', () => {\n        if (!this.audioContext) {\n          this.audioContext = new (window.AudioContext || window.webkitAudioContext)();\n        }\n      }, { once: true });\n    }\n  }\n  \n  provideFeedback(type: 'start' | 'stop' | 'command', command?: string) {\n    // Visuelles Feedback\n    this.provideVisualFeedback(type, command);\n    \n    // Akustisches Feedback\n    this.provideAudioFeedback(type);\n  }\n  \n  private provideVisualFeedback(type: 'start' | 'stop' | 'command', command?: string) {\n    // Implementierung des visuellen Feedbacks\n    // z.B. Anzeigen eines Indikators oder einer Benachrichtigung\n    const feedbackElement = document.getElementById('voice-feedback');\n    if (feedbackElement) {\n      switch (type) {\n        case 'start':\n          feedbackElement.textContent = 'Spracherkennung aktiv';\n          feedbackElement.classList.add('listening');\n          break;\n        case 'stop':\n          feedbackElement.textContent = 'Spracherkennung gestoppt';\n          feedbackElement.classList.remove('listening');\n          break;\n        case 'command':\n          feedbackElement.textContent = `Befehl erkannt: ${command}`;\n          break;\n      }\n    }\n  }\n  \n  private provideAudioFeedback(type: 'start' | 'stop' | 'command') {\n    if (!this.audioContext) return;\n    \n    // Einfaches akustisches Feedback\n    const oscillator = this.audioContext.createOscillator();\n    const gainNode = this.audioContext.createGain();\n    \n    oscillator.connect(gainNode);\n    gainNode.connect(this.audioContext.destination);\n    \n    // Verschiedene T\xf6ne f\xfcr verschiedene Feedback-Typen\n    switch (type) {\n      case 'start':\n        oscillator.frequency.value = 880; // A5\n        break;\n      case 'stop':\n        oscillator.frequency.value = 440; // A4\n        break;\n      case 'command':\n        oscillator.frequency.value = 660; // E5\n        break;\n    }\n    \n    gainNode.gain.value = 0.1;\n    oscillator.start();\n    \n    // Kurzer Ton\n    setTimeout(() => {\n      oscillator.stop();\n    }, 100);\n  }\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"5-implementieren-des-voicecontrolmanagers",children:"5. Implementieren des VoiceControlManagers"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/VoiceControlManager.ts\nimport { RecognitionEngine } from './engines/RecognitionEngine';\nimport { WebSpeechRecognitionEngine } from './engines/WebSpeechRecognitionEngine';\nimport { TensorFlowRecognitionEngine } from './engines/TensorFlowRecognitionEngine';\nimport { CommandProcessor } from './CommandProcessor';\nimport { FeedbackManager } from './FeedbackManager';\n\nexport type EngineType = 'webSpeech' | 'tensorFlow' | 'external';\n\nexport class VoiceControlManager {\n  private recognitionEngine: RecognitionEngine;\n  private commandProcessor: CommandProcessor;\n  private feedbackManager: FeedbackManager;\n  private registeredComponents: Map<string, string[]> = new Map();\n\n  public onRecognitionResult: (text: string) => void = () => {};\n  public onCommandRecognized: (command: string, target: string) => void = () => {};\n  public onListeningStateChanged: (isListening: boolean) => void = () => {};\n\n  constructor(engineType: EngineType = 'webSpeech', language = 'de-DE') {\n    // Initialisiere die entsprechende Engine basierend auf dem Typ\n    switch (engineType) {\n      case 'tensorFlow':\n        this.recognitionEngine = new TensorFlowRecognitionEngine();\n        break;\n      case 'external':\n        // Implementierung f\xfcr externe Dienste\n        this.recognitionEngine = new WebSpeechRecognitionEngine(language); // Fallback\n        break;\n      case 'webSpeech':\n      default:\n        this.recognitionEngine = new WebSpeechRecognitionEngine(language);\n        break;\n    }\n\n    this.commandProcessor = new CommandProcessor();\n    this.feedbackManager = new FeedbackManager();\n\n    this.setupEventListeners();\n  }\n\n  private setupEventListeners() {\n    this.recognitionEngine.onResult = (text) => {\n      this.onRecognitionResult(text);\n      const { command, targetId } = this.commandProcessor.processCommand(\n        text,\n        this.registeredComponents\n      );\n      \n      if (command && targetId) {\n        this.onCommandRecognized(command, targetId);\n        this.feedbackManager.provideFeedback('command', command);\n      }\n    };\n\n    this.recognitionEngine.onStateChange = (isListening) => {\n      this.onListeningStateChanged(isListening);\n    };\n  }\n\n  public startListening() {\n    this.recognitionEngine.start();\n    this.feedbackManager.provideFeedback('start');\n  }\n\n  public stopListening() {\n    this.recognitionEngine.stop();\n    this.feedbackManager.provideFeedback('stop');\n  }\n\n  public registerComponent(id: string, commands: string[]) {\n    this.registeredComponents.set(id, commands);\n  }\n\n  public unregisterComponent(id: string) {\n    this.registeredComponents.delete(id);\n  }\n\n  public cleanup() {\n    this.recognitionEngine.cleanup();\n  }\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"6-implementieren-des-voicecontrolproviders",children:"6. Implementieren des VoiceControlProviders"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"// src/voice-control/VoiceControlProvider.tsx\nimport React, { createContext, useContext, useState, useEffect, ReactNode } from 'react';\nimport { VoiceControlManager, EngineType } from './VoiceControlManager';\n\ninterface VoiceControlContextType {\n  isListening: boolean;\n  startListening: () => void;\n  stopListening: () => void;\n  recognizedText: string;\n  lastCommand: string;\n  targetComponent: string | null;\n  registerComponent: (id: string, commands: string[]) => void;\n  unregisterComponent: (id: string) => void;\n}\n\ninterface VoiceControlProviderProps {\n  children: ReactNode;\n  engineType?: EngineType;\n  language?: string;\n  debug?: boolean;\n}\n\nconst VoiceControlContext = createContext<VoiceControlContextType | undefined>(undefined);\n\nexport const VoiceControlProvider: React.FC<VoiceControlProviderProps> = ({\n  children,\n  engineType = 'webSpeech',\n  language = 'de-DE',\n  debug = false,\n}) => {\n  const [manager] = useState(() => new VoiceControlManager(engineType, language));\n  const [isListening, setIsListening] = useState(false);\n  const [recognizedText, setRecognizedText] = useState('');\n  const [lastCommand, setLastCommand] = useState('');\n  const [targetComponent, setTargetComponent] = useState<string | null>(null);\n\n  useEffect(() => {\n    manager.onRecognitionResult = (text) => {\n      setRecognizedText(text);\n      if (debug) {\n        console.log('Recognized text:', text);\n      }\n    };\n\n    manager.onCommandRecognized = (command, target) => {\n      setLastCommand(command);\n      setTargetComponent(target);\n      if (debug) {\n        console.log(`Command recognized: ${command}, Target: ${target}`);\n      }\n    };\n\n    manager.onListeningStateChanged = (listening) => {\n      setIsListening(listening);\n      if (debug) {\n        console.log('Listening state changed:', listening);\n      }\n    };\n\n    return () => {\n      manager.cleanup();\n    };\n  }, [manager, debug]);\n\n  const startListening = () => {\n    manager.startListening();\n  };\n\n  const stopListening = () => {\n    manager.stopListening();\n  };\n\n  const registerComponent = (id: string, commands: string[]) => {\n    manager.registerComponent(id, commands);\n    if (debug) {\n      console.log(`Registered component ${id} with commands:`, commands);\n    }\n  };\n\n  const unregisterComponent = (id: string) => {\n    manager.unregisterComponent(id);\n    if (debug) {\n      console.log(`Unregistered component ${id}`);\n    }\n  };\n\n  // Render Debug-UI wenn debug=true\n  const renderDebugUI = () => {\n    if (!debug) return null;\n    \n    return (\n      <div className=\"voice-control-debug\" style={{\n        position: 'fixed',\n        bottom: '10px',\n        right: '10px',\n        padding: '10px',\n        backgroundColor: 'rgba(0, 0, 0, 0.7)',\n        color: 'white',\n        borderRadius: '5px',\n        zIndex: 9999,\n        maxWidth: '300px',\n        fontSize: '12px'\n      }}>\n        <h4>Voice Control Debug</h4>\n        <div>Status: {isListening ? 'Listening' : 'Not Listening'}</div>\n        <div>Recognized: {recognizedText}</div>\n        <div>Last Command: {lastCommand}</div>\n        <div>Target: {targetComponent}</div>\n        <button onClick={isListening ? stopListening : startListening}>\n          {isListening ? 'Stop' : 'Start'} Listening\n        </button>\n      </div>\n    );\n  };\n\n  return (\n    <VoiceControlContext.Provider\n      value={{\n        isListening,\n        startListening,\n        stopListening,\n        recognizedText,\n        lastCommand,\n        targetComponent,\n        registerComponent,\n        unregisterComponent,\n      }}\n    >\n      {children}\n      {renderDebugUI()}\n      <div id=\"voice-feedback\" aria-live=\"polite\" className=\"voice-feedback\" style={{\n        position: 'fixed',\n        top: '10px',\n        right: '10px',\n        padding: '5px 10px',\n        backgroundColor: isListening ? 'rgba(0, 128, 0, 0.7)' : 'rgba(128, 128, 128, 0.7)',\n        color: 'white',\n        borderRadius: '5px',\n        zIndex: 9998,\n        transition: 'all 0.3s ease',\n        opacity: isListening ? 1 : 0,\n        pointerEvents: 'none'\n      }}>\n        {isListening ? 'Spracherkennung aktiv' : 'Spracherkennung inaktiv'}\n      </div>\n    </VoiceControlContext.Provider>\n  );\n};\n\nexport const useVoiceControl = () => {\n  const context = useContext(VoiceControlContext);\n  if (context === undefined) {\n    throw new Error('useVoiceControl must be used within a VoiceControlProvider');\n  }\n  return context;\n};\n"})}),"\n",(0,o.jsx)(n.h3,{id:"7-implementieren-des-withvoicecontrol-hoc",children:"7. Implementieren des withVoiceControl HOC"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"// src/voice-control/withVoiceControl.tsx\nimport React, { useEffect, useRef, useId } from 'react';\nimport { useVoiceControl } from './VoiceControlProvider';\n\nexport interface VoiceControlProps {\n  voiceCommands?: string[];\n  voiceEnabled?: boolean;\n  onVoiceCommand?: (command: string) => void;\n}\n\nexport function withVoiceControl<P extends object>(\n  Component: React.ComponentType<P>,\n  defaultCommands: string[] = []\n) {\n  return React.forwardRef<unknown, P & VoiceControlProps>((props, ref) => {\n    const {\n      voiceCommands = defaultCommands,\n      voiceEnabled = true,\n      onVoiceCommand,\n      ...rest\n    } = props;\n\n    const id = useId();\n    const { registerComponent, unregisterComponent, targetComponent, lastCommand } = useVoiceControl();\n    const componentRef = useRef<HTMLElement>(null);\n\n    useEffect(() => {\n      if (voiceEnabled && voiceCommands.length > 0) {\n        registerComponent(id, voiceCommands);\n      }\n\n      return () => {\n        if (voiceEnabled) {\n          unregisterComponent(id);\n        }\n      };\n    }, [id, registerComponent, unregisterComponent, voiceEnabled, voiceCommands]);\n\n    useEffect(() => {\n      if (targetComponent === id && lastCommand && onVoiceCommand) {\n        onVoiceCommand(lastCommand);\n      }\n    }, [id, lastCommand, onVoiceCommand, targetComponent]);\n\n    return <Component ref={ref || componentRef} {...(rest as P)} />;\n  });\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"8-erstellen-der-exportdatei",children:"8. Erstellen der Exportdatei"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/index.ts\nexport { VoiceControlProvider, useVoiceControl } from './VoiceControlProvider';\nexport { withVoiceControl } from './withVoiceControl';\nexport type { VoiceControlProps } from './withVoiceControl';\nexport { VoiceControlManager } from './VoiceControlManager';\nexport type { EngineType } from './VoiceControlManager';\n"})}),"\n",(0,o.jsx)(n.h2,{id:"komponenten-integration",children:"Komponenten-Integration"}),"\n",(0,o.jsx)(n.p,{children:"Nachdem Sie die Basisinfrastruktur implementiert haben, k\xf6nnen Sie sprachgesteuerte Versionen der Smolitux-UI-Komponenten erstellen."}),"\n",(0,o.jsx)(n.h3,{id:"beispiel-sprachgesteuerter-button",children:"Beispiel: Sprachgesteuerter Button"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"// src/components/voice/VoiceButton.tsx\nimport React from 'react';\nimport { Button, ButtonProps } from '@smolitux/core';\nimport { withVoiceControl, VoiceControlProps } from '../../voice-control';\n\nexport type VoiceButtonProps = ButtonProps & VoiceControlProps;\n\nconst VoiceButtonBase: React.FC<VoiceButtonProps> = ({ \n  onVoiceCommand, \n  onClick,\n  children,\n  ...props \n}) => {\n  const handleClick = (event: React.MouseEvent<HTMLButtonElement>) => {\n    if (onClick) {\n      onClick(event);\n    }\n  };\n\n  const handleVoiceCommand = (command: string) => {\n    if (command.toLowerCase() === 'klick' || command.toLowerCase() === 'click') {\n      // Simuliere einen Klick-Event\n      const buttonElement = document.getElementById(props.id || '');\n      if (buttonElement) {\n        buttonElement.click();\n      }\n    }\n\n    if (onVoiceCommand) {\n      onVoiceCommand(command);\n    }\n  };\n\n  return (\n    <Button\n      onClick={handleClick}\n      onVoiceCommand={handleVoiceCommand}\n      {...props}\n    >\n      {children}\n    </Button>\n  );\n};\n\nexport const VoiceButton = withVoiceControl(VoiceButtonBase, ['klick', 'click']);\n"})}),"\n",(0,o.jsx)(n.h3,{id:"beispiel-sprachgesteuertes-eingabefeld",children:"Beispiel: Sprachgesteuertes Eingabefeld"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"// src/components/voice/VoiceInput.tsx\nimport React, { useState } from 'react';\nimport { Input, InputProps } from '@smolitux/core';\nimport { withVoiceControl, VoiceControlProps } from '../../voice-control';\n\nexport type VoiceInputProps = InputProps & VoiceControlProps;\n\nconst VoiceInputBase: React.FC<VoiceInputProps> = ({ \n  onVoiceCommand, \n  onChange,\n  value,\n  ...props \n}) => {\n  const [inputValue, setInputValue] = useState(value || '');\n\n  const handleChange = (event: React.ChangeEvent<HTMLInputElement>) => {\n    setInputValue(event.target.value);\n    if (onChange) {\n      onChange(event);\n    }\n  };\n\n  const handleVoiceCommand = (command: string) => {\n    if (command.toLowerCase().startsWith('eingabe ')) {\n      // Extrahiere den Text nach \"eingabe \"\n      const text = command.substring(8);\n      \n      // Setze den Wert und simuliere ein Change-Event\n      setInputValue(text);\n      \n      const inputElement = document.getElementById(props.id || '') as HTMLInputElement;\n      if (inputElement) {\n        inputElement.value = text;\n        \n        // Erstelle und dispatche ein synthetisches Event\n        const event = new Event('input', { bubbles: true });\n        inputElement.dispatchEvent(event);\n        \n        // Fokussiere das Element\n        inputElement.focus();\n      }\n    } else if (command.toLowerCase() === 'l\xf6schen') {\n      // L\xf6sche den Inhalt\n      setInputValue('');\n      \n      const inputElement = document.getElementById(props.id || '') as HTMLInputElement;\n      if (inputElement) {\n        inputElement.value = '';\n        \n        // Erstelle und dispatche ein synthetisches Event\n        const event = new Event('input', { bubbles: true });\n        inputElement.dispatchEvent(event);\n      }\n    }\n\n    if (onVoiceCommand) {\n      onVoiceCommand(command);\n    }\n  };\n\n  return (\n    <Input\n      value={inputValue}\n      onChange={handleChange}\n      {...props}\n    />\n  );\n};\n\nexport const VoiceInput = withVoiceControl(\n  VoiceInputBase, \n  ['eingabe', 'l\xf6schen']\n);\n"})}),"\n",(0,o.jsx)(n.h3,{id:"beispiel-sprachgesteuertes-auswahlfeld",children:"Beispiel: Sprachgesteuertes Auswahlfeld"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"// src/components/voice/VoiceSelect.tsx\nimport React, { useState } from 'react';\nimport { Select, SelectProps } from '@smolitux/core';\nimport { withVoiceControl, VoiceControlProps } from '../../voice-control';\n\nexport type VoiceSelectProps = SelectProps & VoiceControlProps;\n\nconst VoiceSelectBase: React.FC<VoiceSelectProps> = ({ \n  onVoiceCommand, \n  onChange,\n  options = [],\n  value,\n  ...props \n}) => {\n  const [selectedValue, setSelectedValue] = useState(value);\n\n  const handleChange = (event: React.ChangeEvent<HTMLSelectElement>) => {\n    setSelectedValue(event.target.value);\n    if (onChange) {\n      onChange(event);\n    }\n  };\n\n  const handleVoiceCommand = (command: string) => {\n    const lowerCommand = command.toLowerCase();\n    \n    // Pr\xfcfe, ob der Befehl \"w\xe4hle X\" oder \"option X w\xe4hlen\" ist\n    if (lowerCommand.startsWith('w\xe4hle ') || lowerCommand.includes(' w\xe4hlen')) {\n      // Extrahiere den Optionsnamen\n      let optionName = '';\n      if (lowerCommand.startsWith('w\xe4hle ')) {\n        optionName = command.substring(6).toLowerCase();\n      } else {\n        optionName = command.split(' w\xe4hlen')[0].toLowerCase();\n      }\n      \n      // Finde die passende Option\n      const matchingOption = options.find(option => {\n        const optionLabel = typeof option === 'string' \n          ? option.toLowerCase() \n          : (option.label || '').toLowerCase();\n        return optionLabel === optionName;\n      });\n      \n      if (matchingOption) {\n        const optionValue = typeof matchingOption === 'string' \n          ? matchingOption \n          : matchingOption.value;\n        \n        // Setze den Wert und simuliere ein Change-Event\n        setSelectedValue(optionValue);\n        \n        const selectElement = document.getElementById(props.id || '') as HTMLSelectElement;\n        if (selectElement) {\n          selectElement.value = optionValue;\n          \n          // Erstelle und dispatche ein synthetisches Event\n          const event = new Event('change', { bubbles: true });\n          selectElement.dispatchEvent(event);\n        }\n      }\n    }\n\n    if (onVoiceCommand) {\n      onVoiceCommand(command);\n    }\n  };\n\n  return (\n    <Select\n      value={selectedValue}\n      onChange={handleChange}\n      options={options}\n      {...props}\n    />\n  );\n};\n\nexport const VoiceSelect = withVoiceControl(\n  VoiceSelectBase, \n  ['w\xe4hle', 'option w\xe4hlen']\n);\n"})}),"\n",(0,o.jsx)(n.h2,{id:"tensorflowjs-integration",children:"TensorFlow.js-Integration"}),"\n",(0,o.jsx)(n.p,{children:"F\xfcr Anwendungen, die TensorFlow.js verwenden, implementieren Sie die TensorFlow Recognition Engine:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/engines/TensorFlowRecognitionEngine.ts\nimport * as tf from '@tensorflow/tfjs';\nimport * as speech from '@tensorflow-models/speech-commands';\nimport { RecognitionEngine } from './RecognitionEngine';\n\nexport class TensorFlowRecognitionEngine implements RecognitionEngine {\n  private model: speech.SpeechCommandRecognizer | null = null;\n  private listening = false;\n  private commandVocabulary: string[] = [];\n\n  public onResult: (text: string) => void = () => {};\n  public onStateChange: (isListening: boolean) => void = () => {};\n\n  constructor() {\n    this.initModel();\n  }\n\n  private async initModel() {\n    try {\n      // Lade das Modell\n      this.model = speech.create('BROWSER_FFT');\n      await this.model.ensureModelLoaded();\n      \n      // Hole verf\xfcgbare Befehle\n      this.commandVocabulary = this.model.wordLabels();\n      \n      // Konfiguriere das Modell\n      this.model.params().scoreThreshold = 0.75;\n      \n      console.log('TensorFlow.js speech model loaded successfully');\n      console.log('Available commands:', this.commandVocabulary);\n    } catch (error) {\n      console.error('Failed to load TensorFlow.js speech model:', error);\n    }\n  }\n\n  public async start() {\n    if (!this.model) {\n      await this.initModel();\n    }\n    \n    if (this.model && !this.listening) {\n      this.listening = true;\n      this.onStateChange(true);\n      \n      this.model.listen(\n        result => {\n          const scores = Array.from(result.scores);\n          const maxScore = Math.max(...scores);\n          const maxScoreIndex = scores.indexOf(maxScore);\n          \n          if (maxScore > this.model!.params().scoreThreshold) {\n            const recognizedCommand = this.commandVocabulary[maxScoreIndex];\n            this.onResult(recognizedCommand);\n          }\n        },\n        {\n          includeSpectrogram: false,\n          probabilityThreshold: 0.75,\n          overlapFactor: 0.5\n        }\n      );\n    }\n  }\n\n  public stop() {\n    if (this.model && this.listening) {\n      this.model.stopListening();\n      this.listening = false;\n      this.onStateChange(false);\n    }\n  }\n\n  public cleanup() {\n    this.stop();\n    if (this.model) {\n      this.model.stopListening();\n    }\n  }\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"anpassung-des-voicecontrolproviders-f\xfcr-tensorflowjs",children:"Anpassung des VoiceControlProviders f\xfcr TensorFlow.js"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"// In Ihrer App-Komponente\nimport { VoiceControlProvider } from './voice-control';\n\nfunction App() {\n  return (\n    <VoiceControlProvider engineType=\"tensorFlow\">\n      <YourApp />\n    </VoiceControlProvider>\n  );\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"testen-und-debugging",children:"Testen und Debugging"}),"\n",(0,o.jsx)(n.h3,{id:"unit-tests-f\xfcr-die-sprachsteuerung",children:"Unit-Tests f\xfcr die Sprachsteuerung"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/__tests__/CommandProcessor.test.ts\nimport { CommandProcessor } from '../CommandProcessor';\n\ndescribe('CommandProcessor', () => {\n  let processor: CommandProcessor;\n  let registeredComponents: Map<string, string[]>;\n\n  beforeEach(() => {\n    processor = new CommandProcessor();\n    registeredComponents = new Map();\n    registeredComponents.set('button1', ['klick', 'dr\xfccken']);\n    registeredComponents.set('input1', ['eingabe', 'l\xf6schen']);\n  });\n\n  test('should identify command and target for exact match', () => {\n    const result = processor.processCommand('klick', registeredComponents);\n    expect(result).toEqual({ command: 'klick', targetId: 'button1' });\n  });\n\n  test('should identify command and target for partial match', () => {\n    const result = processor.processCommand('bitte klick den button', registeredComponents);\n    expect(result).toEqual({ command: 'klick', targetId: 'button1' });\n  });\n\n  test('should return null for unrecognized commands', () => {\n    const result = processor.processCommand('unbekannter befehl', registeredComponents);\n    expect(result).toEqual({ command: null, targetId: null });\n  });\n});\n"})}),"\n",(0,o.jsx)(n.h3,{id:"debugging-tipps",children:"Debugging-Tipps"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Aktivieren des Debug-Modus"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"<VoiceControlProvider debug={true}>\n  <YourApp />\n</VoiceControlProvider>\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"\xdcberpr\xfcfen der Browser-Unterst\xfctzung"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"function checkSpeechRecognitionSupport() {\n  return 'SpeechRecognition' in window || 'webkitSpeechRecognition' in window;\n}\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Testen der Mikrofon-Zugriffsrechte"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"async function checkMicrophonePermission() {\n  try {\n    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n    stream.getTracks().forEach(track => track.stop());\n    return true;\n  } catch (error) {\n    console.error('Microphone permission denied:', error);\n    return false;\n  }\n}\n"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"leistungsoptimierung",children:"Leistungsoptimierung"}),"\n",(0,o.jsx)(n.h3,{id:"lazy-loading-der-sprachsteuerung",children:"Lazy Loading der Sprachsteuerung"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"// src/App.tsx\nimport React, { lazy, Suspense, useState } from 'react';\n\n// Lazy-Laden des VoiceControlProviders\nconst VoiceControlProvider = lazy(() => import('./voice-control/VoiceControlProvider'));\n\nfunction App() {\n  const [voiceControlEnabled, setVoiceControlEnabled] = useState(false);\n\n  return (\n    <div className=\"app\">\n      <button onClick={() => setVoiceControlEnabled(!voiceControlEnabled)}>\n        {voiceControlEnabled ? 'Sprachsteuerung deaktivieren' : 'Sprachsteuerung aktivieren'}\n      </button>\n\n      {voiceControlEnabled ? (\n        <Suspense fallback={<div>Lade Sprachsteuerung...</div>}>\n          <VoiceControlProvider>\n            <YourApp />\n          </VoiceControlProvider>\n        </Suspense>\n      ) : (\n        <YourApp />\n      )}\n    </div>\n  );\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"optimierung-der-tensorflowjs-modelle",children:"Optimierung der TensorFlow.js-Modelle"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/engines/TensorFlowRecognitionEngine.ts\n\n// In der initModel-Methode\nprivate async initModel() {\n  try {\n    // Lade das Modell mit Optimierungen\n    await tf.ready();\n    \n    // Verwende WebGL-Backend f\xfcr GPU-Beschleunigung, wenn verf\xfcgbar\n    if (tf.getBackend() !== 'webgl') {\n      await tf.setBackend('webgl');\n    }\n    \n    // Lade ein quantisiertes Modell f\xfcr geringere Gr\xf6\xdfe\n    const modelOptions = {\n      quantizationBits: 8, // Reduziert die Modellgr\xf6\xdfe\n    };\n    \n    this.model = speech.create('BROWSER_FFT', undefined, modelOptions);\n    await this.model.ensureModelLoaded();\n    \n    // Rest der Methode...\n  } catch (error) {\n    console.error('Failed to load TensorFlow.js speech model:', error);\n  }\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"verwendung-von-webworkers",children:"Verwendung von WebWorkers"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"// src/voice-control/workers/speechRecognitionWorker.ts\n// Dies ist ein separates File, das als WebWorker geladen wird\n\nimport * as tf from '@tensorflow/tfjs';\nimport * as speech from '@tensorflow-models/speech-commands';\n\nlet model: speech.SpeechCommandRecognizer | null = null;\n\n// Initialisiere das Modell\nasync function initModel() {\n  model = speech.create('BROWSER_FFT');\n  await model.ensureModelLoaded();\n  \n  // Informiere den Hauptthread, dass das Modell geladen ist\n  self.postMessage({ type: 'modelLoaded', commands: model.wordLabels() });\n}\n\n// H\xf6re auf Nachrichten vom Hauptthread\nself.addEventListener('message', async (event) => {\n  const { type, data } = event.data;\n  \n  switch (type) {\n    case 'init':\n      await initModel();\n      break;\n    case 'start':\n      if (model) {\n        model.listen(\n          result => {\n            const scores = Array.from(result.scores);\n            const maxScore = Math.max(...scores);\n            const maxScoreIndex = scores.indexOf(maxScore);\n            \n            if (maxScore > model!.params().scoreThreshold) {\n              const recognizedCommand = model!.wordLabels()[maxScoreIndex];\n              self.postMessage({ type: 'result', command: recognizedCommand, score: maxScore });\n            }\n          },\n          {\n            includeSpectrogram: false,\n            probabilityThreshold: 0.75,\n            overlapFactor: 0.5\n          }\n        );\n        self.postMessage({ type: 'listening', status: true });\n      }\n      break;\n    case 'stop':\n      if (model) {\n        model.stopListening();\n        self.postMessage({ type: 'listening', status: false });\n      }\n      break;\n  }\n});\n\n// Informiere den Hauptthread, dass der Worker bereit ist\nself.postMessage({ type: 'ready' });\n"})}),"\n",(0,o.jsx)(n.h2,{id:"barrierefreiheit",children:"Barrierefreiheit"}),"\n",(0,o.jsx)(n.h3,{id:"aria-attribute-f\xfcr-sprachsteuerung",children:"ARIA-Attribute f\xfcr Sprachsteuerung"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:'// Beispiel f\xfcr einen sprachgesteuerten Button mit ARIA-Attributen\n<VoiceButton\n  aria-label="Speichern"\n  aria-describedby="voice-command-hint"\n  voiceCommands={[\'speichern\', \'sichern\']}\n>\n  Speichern\n</VoiceButton>\n\n// Hinweis f\xfcr Sprachbefehle\n<div id="voice-command-hint" className="sr-only">\n  Sie k\xf6nnen diesen Button mit den Sprachbefehlen "speichern" oder "sichern" aktivieren.\n</div>\n'})}),"\n",(0,o.jsx)(n.h3,{id:"tastaturunterst\xfctzung",children:"Tastaturunterst\xfctzung"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"// src/voice-control/VoiceControlProvider.tsx\n\n// F\xfcgen Sie Tastaturunterst\xfctzung zum VoiceControlProvider hinzu\nuseEffect(() => {\n  const handleKeyDown = (event: KeyboardEvent) => {\n    // Alt+V zum Starten/Stoppen der Spracherkennung\n    if (event.altKey && event.key === 'v') {\n      if (isListening) {\n        stopListening();\n      } else {\n        startListening();\n      }\n    }\n  };\n\n  window.addEventListener('keydown', handleKeyDown);\n  return () => {\n    window.removeEventListener('keydown', handleKeyDown);\n  };\n}, [isListening, startListening, stopListening]);\n"})}),"\n",(0,o.jsx)(n.h2,{id:"mehrsprachige-unterst\xfctzung",children:"Mehrsprachige Unterst\xfctzung"}),"\n",(0,o.jsx)(n.h3,{id:"sprachkonfiguration",children:"Sprachkonfiguration"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"// src/App.tsx\nimport { VoiceControlProvider } from './voice-control';\n\nfunction App() {\n  // Sprache basierend auf Benutzereinstellungen oder Browser-Sprache\n  const userLanguage = navigator.language || 'de-DE';\n  \n  return (\n    <VoiceControlProvider language={userLanguage}>\n      <YourApp />\n    </VoiceControlProvider>\n  );\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"lokalisierte-befehle",children:"Lokalisierte Befehle"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"// src/components/voice/localizedCommands.ts\nexport const localizedCommands = {\n  'de-DE': {\n    button: ['klick', 'dr\xfccken'],\n    input: ['eingabe', 'l\xf6schen'],\n    select: ['w\xe4hle', 'option w\xe4hlen'],\n    // ...\n  },\n  'en-US': {\n    button: ['click', 'press'],\n    input: ['input', 'clear'],\n    select: ['select', 'choose option'],\n    // ...\n  },\n  // Weitere Sprachen...\n};\n\n// Verwendung in Komponenten\nimport { localizedCommands } from './localizedCommands';\nimport { useVoiceControl } from '../../voice-control';\n\nfunction MyComponent() {\n  const { language = 'de-DE' } = useVoiceControl();\n  const commands = localizedCommands[language]?.button || localizedCommands['de-DE'].button;\n  \n  return (\n    <VoiceButton voiceCommands={commands}>\n      Click me\n    </VoiceButton>\n  );\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"h\xe4ufig-gestellte-fragen",children:"H\xe4ufig gestellte Fragen"}),"\n",(0,o.jsx)(n.h3,{id:"1-wie-kann-ich-die-spracherkennung-in-meiner-anwendung-aktivieren",children:"1. Wie kann ich die Spracherkennung in meiner Anwendung aktivieren?"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"import { VoiceControlProvider } from '@smolitux/voice-control';\n\nfunction App() {\n  return (\n    <VoiceControlProvider>\n      <YourApp />\n    </VoiceControlProvider>\n  );\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"2-wie-kann-ich-benutzerdefinierte-sprachbefehle-f\xfcr-eine-komponente-definieren",children:"2. Wie kann ich benutzerdefinierte Sprachbefehle f\xfcr eine Komponente definieren?"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"import { VoiceButton } from '@smolitux/voice-control';\n\nfunction MyComponent() {\n  return (\n    <VoiceButton \n      voiceCommands={['speichern', 'formular absenden']}\n      onVoiceCommand={(command) => {\n        console.log(`Sprachbefehl erkannt: ${command}`);\n        // Benutzerdefinierte Logik hier\n      }}\n    >\n      Speichern\n    </VoiceButton>\n  );\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"3-wie-kann-ich-zwischen-verschiedenen-spracherkennungs-backends-wechseln",children:"3. Wie kann ich zwischen verschiedenen Spracherkennungs-Backends wechseln?"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:'// F\xfcr Web Speech API (Standard)\n<VoiceControlProvider engineType="webSpeech">\n  <YourApp />\n</VoiceControlProvider>\n\n// F\xfcr TensorFlow.js\n<VoiceControlProvider engineType="tensorFlow">\n  <YourApp />\n</VoiceControlProvider>\n\n// F\xfcr externe Dienste\n<VoiceControlProvider engineType="external">\n  <YourApp />\n</VoiceControlProvider>\n'})}),"\n",(0,o.jsx)(n.h3,{id:"4-wie-kann-ich-die-spracherkennung-programmatisch-starten-und-stoppen",children:"4. Wie kann ich die Spracherkennung programmatisch starten und stoppen?"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"import { useVoiceControl } from '@smolitux/voice-control';\n\nfunction MyComponent() {\n  const { startListening, stopListening, isListening } = useVoiceControl();\n  \n  return (\n    <div>\n      <button onClick={isListening ? stopListening : startListening}>\n        {isListening ? 'Spracherkennung stoppen' : 'Spracherkennung starten'}\n      </button>\n    </div>\n  );\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"5-wie-kann-ich-die-sprachsteuerung-f\xfcr-bestimmte-komponenten-deaktivieren",children:"5. Wie kann ich die Sprachsteuerung f\xfcr bestimmte Komponenten deaktivieren?"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:"// Deaktivieren der Sprachsteuerung f\xfcr eine einzelne Komponente\n<VoiceButton voiceEnabled={false}>\n  Nicht sprachgesteuert\n</VoiceButton>\n"})}),"\n",(0,o.jsx)(n.h3,{id:"6-wie-kann-ich-die-erkennungsgenauigkeit-verbessern",children:"6. Wie kann ich die Erkennungsgenauigkeit verbessern?"}),"\n",(0,o.jsx)(n.p,{children:"F\xfcr TensorFlow.js-basierte Erkennung k\xf6nnen Sie die Schwellenwerte anpassen:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"// In TensorFlowRecognitionEngine.ts\nthis.model.params().scoreThreshold = 0.85; // H\xf6herer Wert = h\xf6here Genauigkeit, aber weniger Erkennungen\n"})}),"\n",(0,o.jsx)(n.p,{children:"F\xfcr Web Speech API k\xf6nnen Sie die Sprache anpassen:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-tsx",children:'<VoiceControlProvider language="de-DE">\n  <YourApp />\n</VoiceControlProvider>\n'})}),"\n",(0,o.jsx)(n.h3,{id:"7-wie-kann-ich-die-leistung-der-sprachsteuerung-optimieren",children:"7. Wie kann ich die Leistung der Sprachsteuerung optimieren?"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Verwenden Sie Lazy Loading f\xfcr die Sprachsteuerung"}),"\n",(0,o.jsx)(n.li,{children:"Implementieren Sie die Spracherkennung in einem WebWorker"}),"\n",(0,o.jsx)(n.li,{children:"Verwenden Sie quantisierte TensorFlow.js-Modelle"}),"\n",(0,o.jsx)(n.li,{children:"Laden Sie nur die ben\xf6tigten Sprachmodelle"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"8-wie-kann-ich-die-sprachsteuerung-f\xfcr-barrierefreiheit-optimieren",children:"8. Wie kann ich die Sprachsteuerung f\xfcr Barrierefreiheit optimieren?"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"F\xfcgen Sie ARIA-Attribute zu allen sprachgesteuerten Komponenten hinzu"}),"\n",(0,o.jsx)(n.li,{children:"Bieten Sie visuelles und akustisches Feedback f\xfcr Sprachbefehle"}),"\n",(0,o.jsx)(n.li,{children:"Stellen Sie alternative Eingabemethoden (Tastatur, Maus) bereit"}),"\n",(0,o.jsx)(n.li,{children:"Dokumentieren Sie verf\xfcgbare Sprachbefehle f\xfcr Benutzer"}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>c});var i=t(6540);const o={},r=i.createContext(o);function s(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);